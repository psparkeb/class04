{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMslsaWKkjr0+l5Ce55JKB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psparkeb/class04/blob/main/class04(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 498,
      "metadata": {
        "id": "dm_WExVhNgxL"
      },
      "outputs": [],
      "source": [
        "#텐서 플로와 딥러닝의 입문\n",
        "#인공 지능 안에 머신 러닝 안에 딥 러닝\n",
        "#텐서 플로 TensorFlow:2015 구글 브레인 팀에서 공개한 라이브러리(코랩도 구글 거라 연결이 잘 됨.)\n",
        "#                      파이썬 뿐만 아니라 JS Swift 등등을 지원함. 텐서 플로는 딥러닝 연산 처리 라이브러리\n",
        "#                      이름에서 볼 수 있듯이 텐서 Tensor 라고 부르는 데이터를 사용함. \n",
        "#                      노드와 노드를 연결하는 간선 edge로 이루어진 그래프 구조를 통해 데이터를 이동시키면서 연산이 이루어 짐.\n",
        "\n",
        "#텐서플로1과 2가 있는데 차이가 큼.\n",
        "#텐서플로2의 특징: 1) 모델 구조를 만들고 학습을 진행하는 과정이 직관적임. 2) 실행 결과를 즉시 확인할 수 있어 편리함.(인터프리터 형식)\n",
        "#                  3) 파이썬 도구를 사용해서 학습 과정을 설계함.          4) 텐서플로 1은 일종의 컴파일러 방식, 텐서플로 2는 인종의 인터프리터 형식이라고 볼 수 있음.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "mcpKYtJ0QbXG"
      },
      "execution_count": 499,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=1\n",
        "b=2\n",
        "c=tf.math.add(a,b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tELv2r-kRP4R",
        "outputId": "358f921e-0172-4c43-f909-1f9f969eeb86"
      },
      "execution_count": 500,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서플로 자료구조\n",
        "#텐서플로에서 자료를 표현하는 기본 구조는 텐서\n",
        "#0차원 텐서-스칼라 Scalar \n",
        "#1차원 텐서-벡터 Vector\n",
        "#2차원 텐서-행렬 Matrix\n",
        "#고차원 텐서...(행렬이 여러개..)\n",
        "#점>선>면>입체로 변하는 공간 개념으로 생각해야 함.\n",
        "#텐서에서의 각 차원은 각각 고유 정보를 나타내는 축이라고 이해해야 함.\n",
        "#tensor의 사전적 의미: 어떤 방향으로 뻗다, 어떤 방향으로 잡아당기다\n",
        "#즉, 방향성을 갖는 어떤 물리량 -> 벡터\n",
        "#스칼라 Scalar: 스칼라는 정수, 실수와 같은 상수를 나타냄. 양은 나타내지만 방향성은 없음. 따라서 차수가 0 이 됨. 또다른 표현으로 rank-0 텐서(랭크는 텐서의 차수를 나타냄.)"
      ],
      "metadata": {
        "id": "7Sq5bRg_RZdE"
      },
      "execution_count": 501,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=tf.constant(1)\n",
        "b=tf.constant(2)\n",
        "print(a)\n",
        "print(b)\n",
        "#shape=() 차수가 0인 스칼라를 의미함. 정수 1과 2는 0차원 텐서인 스칼라로 저장이 되었다고 말함. \n",
        "#dtype=int32 32비트 정수형"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWyBvvqTTfGl",
        "outputId": "3cff0949-1b4f-4419-83a0-357e7c7c9739"
      },
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.rank(a))\n",
        "#변수 a에 저장된 텐서의 랭크값은 0인 스칼라 텐서."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLqAbx9iTr42",
        "outputId": "655aa2e0-1526-4046-8955-7b9855ad4998"
      },
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서 자료형 변환                                                   \n",
        "a=tf.cast(a,tf.float32)"
      ],
      "metadata": {
        "id": "pdS8rxTEUXsr"
      },
      "execution_count": 504,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEOhVIgVU5aD",
        "outputId": "b8e3d199-504f-4325-931a-c32e3df4462b"
      },
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=tf.cast(b, tf.float32)"
      ],
      "metadata": {
        "id": "0W5QkYbMVFz9"
      },
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSrgIhpAVQ-U",
        "outputId": "4eea72d8-a398-41ce-8eb2-87a24b307fcf"
      },
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서플로에서는 float32를 숫자의 기본 자료형으로 사용함. 실수가 기본형. 그래서 형변환하는 것."
      ],
      "metadata": {
        "id": "bUkhikLSVWVG"
      },
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=tf.math.add(a,b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0pOBDwYVDqr",
        "outputId": "b9a8ec7d-3d07-4e0c-8794-1e39aefaea1f"
      },
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.rank(c) # 0차원의 데이터 타입이므로 int32가 나옴. 0은 정수이므로, 위에는 c에 들어있는 값의 차원이 float32라는 것."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkzmHBMpVweO",
        "outputId": "0669dc3b-c409-4254-cec9-a68cfbfe5b01"
      },
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
            ]
          },
          "metadata": {},
          "execution_count": 510
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.subtract(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H3ZTLB1V5-4",
        "outputId": "99616af3-60b6-435c-d3e4-97a425033f00"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(-1.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.multiply(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1oYvgJZWok",
        "outputId": "1e51425d-3449-4a6c-945a-e7103abee973"
      },
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.divide(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kvz8p4BZf1N",
        "outputId": "c27624bc-14a0-4e4f-896c-155f9a7ab6c3"
      },
      "execution_count": 513,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.5, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.mod(a,b)) #나머지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1xIDa3eZtjn",
        "outputId": "685274b0-d49b-4cee-e61a-2d0aeb7f1b14"
      },
      "execution_count": 514,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.floordiv(a,b)) #몫 잘 안 씀."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN2-NVl3Z2CD",
        "outputId": "5384b426-c6a4-47f5-c14e-cf678967848c"
      },
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#벡터 Vector: 여러 개의 스칼라를 원소로 갖는 1차원의 배열\n",
        "#             스칼라 여러 개가 동일한 축 방향으로 나열되는 개념\n",
        "#             벡터는 원소들로 구성되는 여러 개의 값들이 모여서 하나의 대표성을 갖는 값이 됨. 크기와 방향을 가짐.\n",
        "#             각 원소들의 크기 뿐 아니라 원소들이 나열되는 순서도 의미가 있음.\n",
        "#             형태만 보면 파이썬의 리스트와 유사함.\n",
        "#             벡터는 하나의 축을 갖고 차수가 1인 rank-1 텐서라고 부름."
      ],
      "metadata": {
        "id": "TQYCZlaMZ9Ro"
      },
      "execution_count": 516,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "py_list=[10,20,30]\n",
        "vec1=tf.constant(py_list,dtype=tf.float32)\n",
        "print(vec1) #shape=(가로,세로)이므로 현재 가로만 있는 1차원임."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRHYlCKJZyk4",
        "outputId": "afb8bf36-ab80-4d68-ab92-e4a283c9563a"
      },
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_arr=np.array([10.,10.,10.])\n",
        "vec2=tf.constant(num_arr,dtype=tf.float32)\n",
        "print(vec2) #shape=3 원소의 개수 3개, 가로만 있는 1개의 축"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b2z2n3NbjJK",
        "outputId": "bde011de-f2e4-4393-cc20-ddf93ed81263"
      },
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 10. 10.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.rank(vec1)) # 1차원이며 1은 0차원이고 1의 데이터 타입은 정수32타입.\n",
        "print(tf.rank(vec2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NynoYFpOcJFd",
        "outputId": "9806e0cf-876e-48cb-811b-e7b031f3ae92"
      },
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add1= tf.math.add(vec1,vec2)\n",
        "print(add1)\n",
        "print(tf.rank(add1)) #계산을 할 때는 같은 위치에 있는 원소들끼리 짝을 이루어 계산함. 따라서, 원소 3개를 갖는 벡터 형태가 그대로 유지됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DnmsgbxclBF",
        "outputId": "d38092e4-8462-4cfa-ebd0-aef1376b9b92"
      },
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add2=vec1+vec2\n",
        "print(add2)\n",
        "print(tf.rank(add2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sc-stu4dCVZ",
        "outputId": "b2c41aa7-f2cf-4436-e26f-054cc01d7aae"
      },
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#스칼라와 마찬가지로 벡터도 tf.math 모듈을 통해 다양한 함수를 산술 연산할 수 있음. 이때, 같은 위치에 있는 원소들끼리 연산함."
      ],
      "metadata": {
        "id": "yebCaeLMda2L"
      },
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.subtract(vec1,vec2))\n",
        "print(tf.math.multiply(vec1,vec2))\n",
        "print(tf.math.divide(vec1,vec2))\n",
        "print(tf.math.mod(vec1,vec2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYTcvvKxcjeE",
        "outputId": "ad7ad172-3708-4661-bb9d-687f4927d3eb"
      },
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0. 10. 20.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([100. 200. 300.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec1-vec2)\n",
        "print(vec1*vec2)\n",
        "print(vec1/vec2)\n",
        "print(vec1%vec2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLYRDXXreLVy",
        "outputId": "42220438-4a2a-4d44-b2dd-3b161a876046"
      },
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0. 10. 20.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([100. 200. 300.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#여러 원소들의 합\n",
        "print(tf.reduce_sum(vec1))\n",
        "print(tf.reduce_sum(vec2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlWziejJeVJF",
        "outputId": "bce298ae-625c-4f32-8e96-0230d01c1ca4"
      },
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(60.0, shape=(), dtype=float32)\n",
            "tf.Tensor(30.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 브로드캐스팅\n",
        "print(vec1)\n",
        "print(vec1+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaXrTnLmerE6",
        "outputId": "2b28bb7b-7703-46c6-f033-aa934325e4b3"
      },
      "execution_count": 526,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n",
            "tf.Tensor([11. 21. 31.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 행렬 Matrix: 행렬은 차수가 1인 즉, 벡터를 같은 축 방향으로 여러 개를 나열한 것.\n",
        "#              1차원 벡터 여러 개를 원소로 갖는 배열.\n",
        "#              텐서플로에서는 rank-2 \n",
        "#              pandas에서의 데이터 프레임과 유사함."
      ],
      "metadata": {
        "id": "AFRsxvFNfATg"
      },
      "execution_count": 527,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list=[[10,20],[30,40]] #2차원 리스트 생성\n",
        "mat=tf.constant(list) #텐서 변환\n",
        "print(mat)\n",
        "print(tf.rank(mat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCxHOlmce8V4",
        "outputId": "3bcde808-7d00-444a-a5c2-eb800f992b07"
      },
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10 20]\n",
            " [30 40]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec1=tf.constant([1,0])\n",
        "vec2=tf.constant([-1,2])\n",
        "mat2=tf.stack([vec1,vec2])\n",
        "print(mat2)\n",
        "print(tf.rank(mat2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5p2xEIVgSHI",
        "outputId": "5db75bf9-0c41-419a-f1db-cff65a2ed852"
      },
      "execution_count": 529,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  0]\n",
            " [-1  2]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.defchararray import multiply\n",
        "# 산술 연산\n",
        "mul=tf.math.multiply(mat,mat2)\n",
        "print(mul)\n",
        "print(tf.rank(mul))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKtaichgg7EF",
        "outputId": "2c05a16a-2eed-4fe3-ff29-ed788f959a8a"
      },
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 10   0]\n",
            " [-30  80]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.subtract(mat,mat2))\n",
        "print(tf.math.multiply(mat,mat2))\n",
        "print(tf.math.divide(mat,mat2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjH6nkuChxN5",
        "outputId": "3bb286b7-a143-49b3-fa7f-435226e57ca7"
      },
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 9 20]\n",
            " [31 38]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 10   0]\n",
            " [-30  80]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 10.  inf]\n",
            " [-30.  20.]], shape=(2, 2), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat)\n",
        "bc=tf.math.multiply(mat,3)\n",
        "bc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d23wefDHiEsx",
        "outputId": "fb6bbf46-f839-43c4-cb73-e89fea551c06"
      },
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10 20]\n",
            " [30 40]], shape=(2, 2), dtype=int32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 30,  60],\n",
              "       [ 90, 120]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add2=mat+mat2\n",
        "add2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0KwpUg4iXfj",
        "outputId": "8e8bee55-5af0-4423-e5c2-1668dbe81c2b"
      },
      "execution_count": 533,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[11, 20],\n",
              "       [29, 42]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 533
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서를 넘파이로 변환\n",
        "np_arr=mat.numpy()\n",
        "np_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwJT_31uiszl",
        "outputId": "093ad8cb-57b8-4087-97f6-ce2ed04d177f"
      },
      "execution_count": 534,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10, 20],\n",
              "       [30, 40]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 534
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(np_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkZyE5y0i69p",
        "outputId": "d9dc829d-6568-4b64-f18a-0a14a25a159e"
      },
      "execution_count": 535,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 535
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indexing 인덱싱: 위치를 기준으로 원소를 추출하는 방법, 파이썬 리스트 또는 넘파일 배열의 인덱싱과 유사함.\n",
        "#                 0부터 시작하고 마지막은 -1로 나타냄. 하나만 추출할 뿐만 아니라 여러 원소를 추출하는 슬라이싱 가능."
      ],
      "metadata": {
        "id": "5d4ov7vVi_Cu"
      },
      "execution_count": 536,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec=tf.constant([10,20,30,40,50])\n",
        "print(vec)  #shape 5개 원소의 1차원 텐서인 벡터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhof_RNniUBn",
        "outputId": "2a5fbb4d-9eca-4212-bd60-3bbabc944f76"
      },
      "execution_count": 537,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 20 30 40 50], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY_--c6in3Fv",
        "outputId": "52ec625f-e43f-4ae5-9128-cd7028e45369"
      },
      "execution_count": 538,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK9_dD9soHH0",
        "outputId": "88be5f9b-2bcf-41d3-c63b-47f2a625cb9f"
      },
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(50, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec[:3]) #1차원의 3개 원소 벡터로 나옴."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ24pvbBoVhW",
        "outputId": "72ff7cfa-6d5a-41a2-b18d-d59a99dd1494"
      },
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat=tf.constant([[10,20,30],[40,50,60]])\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfvjVUvAoeIy",
        "outputId": "b75900e7-a20f-42b6-d834-70efb14a790a"
      },
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[10 20 30]\n",
            " [40 50 60]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat[0,:]) #0번째 행의 모든 열"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwwMOio0o4uF",
        "outputId": "f26ff1f9-2462-4812-8b28-c4cc33a96e67"
      },
      "execution_count": 542,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat[:,1]) #모든 행의 1열만 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nvHPeNBo-5I",
        "outputId": "ff43ccb8-bd1c-4aff-b9f9-0034f065bdd6"
      },
      "execution_count": 543,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([20 50], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#형태 변환 reshape : 앞으로 머신 러닝, 딥러닝에서 텐서 형태를 변환하는 것은 매우 중요함!!"
      ],
      "metadata": {
        "id": "3HiEf4-ipMth"
      },
      "execution_count": 544,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=tf.constant(range(0,24))\n",
        "tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSnzDst0ozRu",
        "outputId": "75cd777c-77d6-4db5-aa92-9f226f76fedf"
      },
      "execution_count": 545,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 545
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (24, ) -> (3,8) 24개의 1차원 자료를 3행,8열의 2차원 자료로 변환\n",
        "tensor1=tf.reshape(tensor,[3,8])\n",
        "print(tensor1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r55QtE3OqR6s",
        "outputId": "0489fbfc-d6fb-4eb0-b624-d6defc020e31"
      },
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7]\n",
            " [ 8  9 10 11 12 13 14 15]\n",
            " [16 17 18 19 20 21 22 23]], shape=(3, 8), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-1을 지정하면 '어떤 값이 와도 상관 없음' 이라는 의미.\n",
        "tensor2=tf.reshape(tensor1,[-1,4]) #행은 상관없고 열만 4개로 해 줘~\n",
        "print(tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdtBdcdQqpmD",
        "outputId": "1c4bb015-5e3e-4c25-82cb-933596c276ec"
      },
      "execution_count": 547,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]\n",
            " [16 17 18 19]\n",
            " [20 21 22 23]], shape=(6, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor3=tf.reshape(tensor2,[-1]) #그냥 1차원이 됨. 배열을 구성하는 원소가 매우 많고 배열 구조를 알지 못할 때 -1을 사용하면 편리함.\n",
        "print(tensor3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPNhTRqQrLLH",
        "outputId": "abc8860a-3905-4121-8349-5d7d7a61e234"
      },
      "execution_count": 548,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor4=tf.reshape(tensor3,[-1,3,4]) #다차원 텐서 : 전체 개수는 2개, 3행 4열\n",
        "print(tensor4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVpmK3zErdv5",
        "outputId": "e6dfd2a0-5ed6-40fd-fd53-ce9b6385d31b"
      },
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3]\n",
            "  [ 4  5  6  7]\n",
            "  [ 8  9 10 11]]\n",
            "\n",
            " [[12 13 14 15]\n",
            "  [16 17 18 19]\n",
            "  [20 21 22 23]]], shape=(2, 3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor5=tf.reshape(tensor4,[3,2,4]) # 2행 4열\n",
        "print(tensor5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtwpH0Fmr7Zb",
        "outputId": "3a4cbc38-bfbf-4db5-a0c6-7d9141de65c5"
      },
      "execution_count": 550,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3]\n",
            "  [ 4  5  6  7]]\n",
            "\n",
            " [[ 8  9 10 11]\n",
            "  [12 13 14 15]]\n",
            "\n",
            " [[16 17 18 19]\n",
            "  [20 21 22 23]]], shape=(3, 2, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor6=tf.reshape(tensor5,[3,2,2,2])\n",
        "print(tensor6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQOcIPsEsRp-",
        "outputId": "213ea69c-6e0c-4f7f-8d05-76cb05b20a76"
      },
      "execution_count": 551,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[ 0  1]\n",
            "   [ 2  3]]\n",
            "\n",
            "  [[ 4  5]\n",
            "   [ 6  7]]]\n",
            "\n",
            "\n",
            " [[[ 8  9]\n",
            "   [10 11]]\n",
            "\n",
            "  [[12 13]\n",
            "   [14 15]]]\n",
            "\n",
            "\n",
            " [[[16 17]\n",
            "   [18 19]]\n",
            "\n",
            "  [[20 21]\n",
            "   [22 23]]]], shape=(3, 2, 2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.Variable 변수: 텐서플로의 변수의 특징\n",
        "#                   텐서 플로는 그래프 구조를 이용하여 복잡한 미분 연산을 함. 이때 수많은 미분 연산을 반복하게 됨. 각각의 중간 연산 결과를 저장하는 용도로도 변수를 이용하게 됨.\n",
        "#                   모델을 학습하는 중간 단계마다 모델의 가중치를 변수에 저장하고 계속 반복하면서 변수 값을 업데이트 함.\n",
        "tensor1=tf.constant([[0,2,3],[3,4,5]])\n",
        "print(tensor1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrje3WQSsgUm",
        "outputId": "fc3dd26f-8216-4ae4-f7e4-054986107f73"
      },
      "execution_count": 552,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 2 3]\n",
            " [3 4 5]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1=tf.Variable(tensor1)\n",
        "print(tensor_var1)\n",
        "#변수는 텐서 구조에 저장되어 있는 값이 달라질 수 있다는 점에서 값을 변경할 수 없는 상수 형태의 텐서를 만드는 constant 함수와 구별됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iXsLG5GtSB1",
        "outputId": "18f92a40-9929-4f1e-a959-e2159fa9e67f"
      },
      "execution_count": 553,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
            "array([[0, 2, 3],\n",
            "       [3, 4, 5]], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1_lKMLsstkWC",
        "outputId": "fbbbbf4a-bd64-460c-f71a-09833629c6ab"
      },
      "execution_count": 554,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Variable:0'"
            ]
          },
          "metadata": {},
          "execution_count": 554
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiwhjT66t-Lr",
        "outputId": "e4cb7a6a-2b23-4f5d-b222-35b86b3854ae"
      },
      "execution_count": 555,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 555
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPro7WtXuAKf",
        "outputId": "7f3ac7d7-6df0-4fdb-c0b3-ffc4810aace5"
      },
      "execution_count": 556,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.int32"
            ]
          },
          "metadata": {},
          "execution_count": 556
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_var1.numpy #변수로 설정하면 변수의 이름 크기 자료형 배열을 확인할 수 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzL3eldguEtU",
        "outputId": "69a5fa4f-0df2-4312-b552-853bc0ecc907"
      },
      "execution_count": 557,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
              "array([[0, 2, 3],\n",
              "       [3, 4, 5]], dtype=int32)>>"
            ]
          },
          "metadata": {},
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assig() 메소드를 이용하여 변수에 새로운 데이터를 할당할 수도 있음.\n",
        "tensor_var1.assign([[1,1,1],[2,2,2]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndNJxiYAuI8O",
        "outputId": "8d7dfaae-e439-47b4-88a3-b06289d47066"
      },
      "execution_count": 558,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=int32, numpy=\n",
              "array([[1, 1, 1],\n",
              "       [2, 2, 2]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#변수를 텐서로 convert_to_tensor() 함수 사용, 텐서로 변환하고 나면 그 텐서의 크기와 값을 변경할 수 없음.(변수는 가능했으나 텐서는 불가)\n",
        "tensor2=tf.convert_to_tensor(tensor_var1)\n",
        "print(tensor2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjRSuM1yu7qZ",
        "outputId": "225bfcde-a68d-4cdb-bcd3-c48e053ac585"
      },
      "execution_count": 559,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 1 1]\n",
            " [2 2 2]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#특히 텐서 변수는 name 속성을 가질 수 있음. \n",
        "tensor_var2=tf.Variable(tensor2,name=\"New Name\")\n",
        "print(tensor_var2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGx4lL2Yvlzd",
        "outputId": "97a5fb03-33f0-45d3-bf83-8cb5243ce594"
      },
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'New Name:0' shape=(2, 3) dtype=int32, numpy=\n",
            "array([[1, 1, 1],\n",
            "       [2, 2, 2]], dtype=int32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서 변수도 텐서 연산과 동일하게 사칙 연산 등의 계산을 처리할 수 있음.\n",
        "tensor_var1+tensor_var2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhYaKppJwEuu",
        "outputId": "c755e3a7-e484-4ca1-f926-616adfe56213"
      },
      "execution_count": 561,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[2, 2, 2],\n",
              "       [4, 4, 4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 561
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#자동 미분 automatic differentiation 아주 어려움~그냥 보기만 \n",
        "#텐서플로는 딥러닝 모델을 구성하는 복잡한 인공 신경망의 각 노드에서 계산되는 미분을 자동으로 계산해 줌. \n",
        "#특히 각 변수의 기울기에 해당하는 그래디언트(접선의 기울기)를 계산하는 데 특화되어 있음.\n",
        "# y=3x-2에서 기울기와 y절편 값을 텐서 자동 미분을 통해 계산"
      ],
      "metadata": {
        "id": "XDsc7g-CwX0N"
      },
      "execution_count": 562,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y=3x-2\n",
        "g=tf.random.Generator.from_seed(2020) #난수로 발생\n",
        "X=g.normal(shape=(10,))\n",
        "Y=3*X-2\n",
        "print(X.numpy())\n",
        "print(Y.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eEwThJ9wCAO",
        "outputId": "d09b2b20-708e-4786-cdf6-922c78238c98"
      },
      "execution_count": 563,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
            "  1.082245    0.6199966  -0.44402212  1.3048344 ]\n",
            "[-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024\n",
            "  1.2467351  -0.14001012 -3.3320663   1.9145031 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#시간 부족으로 자동 미분은 생략ㅎㅎ\n",
        "#Keras 케라스 : 텐서플로와 붙어다니는 아이ㅋㅋ 예전에는 따로였는데 지금은 아예 통합됨. 케라스 만든 사람이 구글에 입사해서 합쳐짐ㅎㅎ\n",
        "#               딥러닝 라이브러리들을 쉽고 간결하게 사용할 수 있도록 하는 것이 목적임. \n",
        "#               케라스 2.3까지는 다른 딥러닝 라이브러리들도 지원했지만 2.4부터는 더이상 다른 라이브러리를 지원하지 않고 오직 텐서플로만 지원함. 구글에 취직을 해서ㅎㅎ\n",
        "# 하이퍼파라미터 hyper parameter : 파이썬의 하이퍼파라미터와는 다른 의미를 가짐.\n",
        "#                                  하이퍼파라미터는 딥러닝뿐 아니라 머신러닝 모델을 훈련할 때 사용자가 직접 설정해주는 설정값을 의미함.\n",
        "#                                  가중치(weights),편향(bias)는 자동으로 업데이트 되지만 학습 속도나 반복 훈련 횟수 등 사용자가 직접 설정해야하는 값들이 많기 때문.\n",
        "#                                  사용자가 어떤 값을 설정하느냐에 따라 모델의 성능과 결과가 많이 달라지기 때문. 따라서 매우 중요함!"
      ],
      "metadata": {
        "id": "RJImQWmWxrJR"
      },
      "execution_count": 564,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 과소 적합 vs 과대 적합"
      ],
      "metadata": {
        "id": "IvadoYEBxpaJ"
      },
      "execution_count": 565,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 에포크 epoch : 딥러닝은 데이터 셋을 학습하는 과정을 매우 많이 반복함. 반복하면서 최적의 모델 가중치를 찾는 과정임. \n",
        "#                반복 훈련을 할 때 학습에 사용하는 1회의 전체 데이터 셋 훈련 루프를 1 epoch 라고 함.(ex: 축구공 사진을 1회에 100장 보여주는 것)\n",
        "#                특히 에폭은 중요한 파라미터임. 과소 적합이라 판단되면 에폭을 늘려서 다시 학습시킬 필요가 있음.\n",
        "#                과대 적합이라 판단되면 에폭을 줄여서 학습을 조기 종료시키는 것이 과대 적합을 방지하는 방법 중 하나임.\n",
        "# 손실 함수 loss function : 예측 값과 정답 간의 차이 또는 오차(출력값과 실제값의 차이)"
      ],
      "metadata": {
        "id": "--j_W2Z9xnY6"
      },
      "execution_count": 566,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "def make_linear(w=0.5,b=0.8,size=50,noise=1.0):\n",
        "  x=np.random.rand(size)\n",
        "  y=w*x+b\n",
        "  noise=np.random.uniform(-abs(noise),abs(noise), size=y.shape)\n",
        "  yy=y+noise\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.plot(x,y,color='r',label=f'y={w}*x+{b}')\n",
        "  plt.scatter(x,yy,label='data')\n",
        "  plt.legend(fontsize=20)\n",
        "  plt.show()\n",
        "  print(f'w:{w}, b:{b}')\n",
        "  return x,yy\n",
        "x,y=make_linear(w=0.3,b=0.5, size=100, noise=0.01)\n",
        "#생성된 y데이터는 y=0.3x+0.5 식과 완전히 일치하지 않고 약간의 노이즈가 추가되었음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "A-fudQtcvj-j",
        "outputId": "2bd9fe80-4049-4533-e83c-51d82bb927a9"
      },
      "execution_count": 567,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w:0.3, b:0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#딥러닝 프로세스(머신 러닝과 거의 비슷)\n",
        "#데이터 로드 -> 데이터 전처리(결측치,이상치) -> 데이터 분할(훈련용,검증용) -> 모델 생성 -> 훈련 -> 검증 -> 예측  "
      ],
      "metadata": {
        "id": "WCNWwfbD5sYW"
      },
      "execution_count": 568,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.arange(1,6)\n",
        "y = 3*x+2\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSD-jnmW5p6i",
        "outputId": "fed06743-bba8-4f4b-f57c-e4e193748406"
      },
      "execution_count": 569,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n",
            "[ 5  8 11 14 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Te7lMayH7rob",
        "outputId": "91160341-9ed1-4a38-eaf7-51b9670dee5c"
      },
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd40f3fec50>]"
            ]
          },
          "metadata": {},
          "execution_count": 570
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서플로 케라스는 일반적으로 세 가지 방식으로 모델을 생성함.\n",
        "# 그 중 가장 간결한 Sequential API 방식을 사용하면 쉽게 만들 수 있음.\n",
        "# 층을 이어 붙이듯 일렬로 연결하는 방식임. 따라서 입력 레이어부터 출력 레이어까지 순서를 가짐.\n",
        "# 입력 데이터는 시퀀스에 가장 앞에 위치하고, 순서대로 각 층을 하나씩 통과하면서 딥러닝 연산을 수행하게 됨.\n",
        "# 직관적으로 구조를 이해할 수 있기 때문에 케라스 중 가장 간단한 방법임.\n",
        "# 2개 이상의 다중 입력이나 다중 출력을 갖는 복잡한 구조를 만들 수는 없음."
      ],
      "metadata": {
        "id": "25cP0uSC7xiP"
      },
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.Sequential([tf.keras.layers.Dense(10),tf.keras.layers.Dense(5),tf.keras.layers.Dense(1)])"
      ],
      "metadata": {
        "id": "oySsgela7o5V"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add함수를 통해서 추가로 층을 추가할 수도 있음.\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Dense(5))\n",
        "model.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "id": "EH5J2FbP9Oou"
      },
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#시퀀스 API를 사용하여 모델을 구성할 때는 반드시 첫 번째 층은 input_shape 매개 변수를 지정해야 함.\n",
        "#input_shape 매개 변수는 주입할 데이터 셋의 shape를 튜플 혹은 리스트로 지정할 수 있음.\n",
        "#예를 들면 데이터 셋의 shape이 (150,4)로 구성되었다고 가정하면 input_shape는 (4,) 혹은 [4]로 지정함.\n",
        "model=tf.keras.Sequential([tf.keras.layers.Dense(10,input_shape=[4]),tf.keras.layers.Dense(5),tf.keras.layers.Dense(1)])"
      ],
      "metadata": {
        "id": "oLg_PMb893k2"
      },
      "execution_count": 574,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#단순 선형 회귀 모델\n",
        "model=tf.keras.Sequential([tf.keras.layers.Dense(1,input_shape=[1])])"
      ],
      "metadata": {
        "id": "x_O1Bloz-kNc"
      },
      "execution_count": 575,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 처음 레이어는 입력층, 마지막 레이어는 출력층, 사이는 은닉층, Dense는 층을 쌓는다는 의미."
      ],
      "metadata": {
        "id": "-gKrOxVe-dZY"
      },
      "execution_count": 576,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() #모델의 요약: 구조를 확인할 수 있고, 층별 노드의 개수가 표기됨. 하단에는 훈련 시 업데이트 할 파라미터의 개수가 표시됨.\n",
        "#                              Total params 모델 내부에 존재하는 모든 파라미터의 합계\n",
        "#                              Trainable params 모델 훈련 시 업데이트 할 파라미터의 총 개수\n",
        "#                              Non-trainable params 훈련 시 업데이트 하지 않을 파라미터의 총 개수\n",
        "#                              단순 선형 회귀 모델에서는 업데이트 파라미터가 가중치 w 편향 b 두 개이다. 따라서 총 params의 개수가 2개로 표기되는 것을 확인할 수 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCPprBQ8-ZTY",
        "outputId": "d453b865-bbba-48dd-f767-1e11871c6832"
      },
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_67 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='mse', metrics=['mse','mae'])\n",
        "# sgd 경사하강법-최적화방법\n",
        "# 평가 지표와 손실 함수: mse 평균 제곱 오차, mae 평균 절대 오차"
      ],
      "metadata": {
        "id": "xEC0rNbrDrj1"
      },
      "execution_count": 578,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history= model.fit(x,y,epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xI2N6vkDdi7",
        "outputId": "cf6f7fe9-ca70-453e-c9b7-5643e6d53bf6"
      },
      "execution_count": 588,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4410e-04 - mse: 1.4410e-04 - mae: 0.0103\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4313e-04 - mse: 1.4313e-04 - mae: 0.0103\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4217e-04 - mse: 1.4217e-04 - mae: 0.0102\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4121e-04 - mse: 1.4121e-04 - mae: 0.0102\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4025e-04 - mse: 1.4025e-04 - mae: 0.0102\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3930e-04 - mse: 1.3930e-04 - mae: 0.0101\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3837e-04 - mse: 1.3837e-04 - mae: 0.0101\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3743e-04 - mse: 1.3743e-04 - mae: 0.0101\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3651e-04 - mse: 1.3651e-04 - mae: 0.0100\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3558e-04 - mse: 1.3558e-04 - mae: 0.0100\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3466e-04 - mse: 1.3466e-04 - mae: 0.0100\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3375e-04 - mse: 1.3375e-04 - mae: 0.0099\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3285e-04 - mse: 1.3285e-04 - mae: 0.0099\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3196e-04 - mse: 1.3196e-04 - mae: 0.0099\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3107e-04 - mse: 1.3107e-04 - mae: 0.0098\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3019e-04 - mse: 1.3019e-04 - mae: 0.0098\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2930e-04 - mse: 1.2930e-04 - mae: 0.0098\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2843e-04 - mse: 1.2843e-04 - mae: 0.0097\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2756e-04 - mse: 1.2756e-04 - mae: 0.0097\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2671e-04 - mse: 1.2671e-04 - mae: 0.0097\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2585e-04 - mse: 1.2585e-04 - mae: 0.0096\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2500e-04 - mse: 1.2500e-04 - mae: 0.0096\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2416e-04 - mse: 1.2416e-04 - mae: 0.0096\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2332e-04 - mse: 1.2332e-04 - mae: 0.0095\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2248e-04 - mse: 1.2248e-04 - mae: 0.0095\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2166e-04 - mse: 1.2166e-04 - mae: 0.0095\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2083e-04 - mse: 1.2083e-04 - mae: 0.0094\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2002e-04 - mse: 1.2002e-04 - mae: 0.0094\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1921e-04 - mse: 1.1921e-04 - mae: 0.0094\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1841e-04 - mse: 1.1841e-04 - mae: 0.0093\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1760e-04 - mse: 1.1760e-04 - mae: 0.0093\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1681e-04 - mse: 1.1681e-04 - mae: 0.0093\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1602e-04 - mse: 1.1602e-04 - mae: 0.0092\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1524e-04 - mse: 1.1524e-04 - mae: 0.0092\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1446e-04 - mse: 1.1446e-04 - mae: 0.0092\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1369e-04 - mse: 1.1369e-04 - mae: 0.0092\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1292e-04 - mse: 1.1292e-04 - mae: 0.0091\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1216e-04 - mse: 1.1216e-04 - mae: 0.0091\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1140e-04 - mse: 1.1140e-04 - mae: 0.0091\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1065e-04 - mse: 1.1065e-04 - mae: 0.0090\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0991e-04 - mse: 1.0991e-04 - mae: 0.0090\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0916e-04 - mse: 1.0916e-04 - mae: 0.0090\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0842e-04 - mse: 1.0842e-04 - mae: 0.0089\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0769e-04 - mse: 1.0769e-04 - mae: 0.0089\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0696e-04 - mse: 1.0696e-04 - mae: 0.0089\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0625e-04 - mse: 1.0625e-04 - mae: 0.0088\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0552e-04 - mse: 1.0552e-04 - mae: 0.0088\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0482e-04 - mse: 1.0482e-04 - mae: 0.0088\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0410e-04 - mse: 1.0410e-04 - mae: 0.0088\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0340e-04 - mse: 1.0340e-04 - mae: 0.0087\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0271e-04 - mse: 1.0271e-04 - mae: 0.0087\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0201e-04 - mse: 1.0201e-04 - mae: 0.0087\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0132e-04 - mse: 1.0132e-04 - mae: 0.0086\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0064e-04 - mse: 1.0064e-04 - mae: 0.0086\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9958e-05 - mse: 9.9958e-05 - mae: 0.0086\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.9282e-05 - mse: 9.9282e-05 - mae: 0.0086\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8615e-05 - mse: 9.8615e-05 - mae: 0.0085\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7953e-05 - mse: 9.7953e-05 - mae: 0.0085\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7291e-05 - mse: 9.7291e-05 - mae: 0.0085\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.6629e-05 - mse: 9.6629e-05 - mae: 0.0084\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5980e-05 - mse: 9.5980e-05 - mae: 0.0084\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5331e-05 - mse: 9.5331e-05 - mae: 0.0084\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4684e-05 - mse: 9.4684e-05 - mae: 0.0084\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4044e-05 - mse: 9.4044e-05 - mae: 0.0083\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3414e-05 - mse: 9.3414e-05 - mae: 0.0083\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2788e-05 - mse: 9.2788e-05 - mae: 0.0083\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2157e-05 - mse: 9.2157e-05 - mae: 0.0082\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1537e-05 - mse: 9.1537e-05 - mae: 0.0082\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0914e-05 - mse: 9.0914e-05 - mae: 0.0082\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.0302e-05 - mse: 9.0302e-05 - mae: 0.0082\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.9701e-05 - mse: 8.9701e-05 - mae: 0.0081\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9089e-05 - mse: 8.9089e-05 - mae: 0.0081\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8489e-05 - mse: 8.8489e-05 - mae: 0.0081\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7892e-05 - mse: 8.7892e-05 - mae: 0.0080\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7299e-05 - mse: 8.7299e-05 - mae: 0.0080\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6709e-05 - mse: 8.6709e-05 - mae: 0.0080\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.6124e-05 - mse: 8.6124e-05 - mae: 0.0080\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5539e-05 - mse: 8.5539e-05 - mae: 0.0079\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4966e-05 - mse: 8.4966e-05 - mae: 0.0079\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4389e-05 - mse: 8.4389e-05 - mae: 0.0079\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.3821e-05 - mse: 8.3821e-05 - mae: 0.0079\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3257e-05 - mse: 8.3257e-05 - mae: 0.0078\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.2693e-05 - mse: 8.2693e-05 - mae: 0.0078\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.2137e-05 - mse: 8.2137e-05 - mae: 0.0078\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1580e-05 - mse: 8.1580e-05 - mae: 0.0078\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1029e-05 - mse: 8.1029e-05 - mae: 0.0077\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0485e-05 - mse: 8.0485e-05 - mae: 0.0077\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9944e-05 - mse: 7.9944e-05 - mae: 0.0077\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9400e-05 - mse: 7.9400e-05 - mae: 0.0076\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.8866e-05 - mse: 7.8866e-05 - mae: 0.0076\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8332e-05 - mse: 7.8332e-05 - mae: 0.0076\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7806e-05 - mse: 7.7806e-05 - mae: 0.0076\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7284e-05 - mse: 7.7284e-05 - mae: 0.0075\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6756e-05 - mse: 7.6756e-05 - mae: 0.0075\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6238e-05 - mse: 7.6238e-05 - mae: 0.0075\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5725e-05 - mse: 7.5725e-05 - mae: 0.0075\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5217e-05 - mse: 7.5217e-05 - mae: 0.0074\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.4710e-05 - mse: 7.4710e-05 - mae: 0.0074\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4206e-05 - mse: 7.4206e-05 - mae: 0.0074\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3703e-05 - mse: 7.3703e-05 - mae: 0.0074\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3209e-05 - mse: 7.3209e-05 - mae: 0.0073\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2716e-05 - mse: 7.2716e-05 - mae: 0.0073\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2222e-05 - mse: 7.2222e-05 - mae: 0.0073\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.1732e-05 - mse: 7.1732e-05 - mae: 0.0073\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1250e-05 - mse: 7.1250e-05 - mae: 0.0072\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0767e-05 - mse: 7.0767e-05 - mae: 0.0072\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0293e-05 - mse: 7.0293e-05 - mae: 0.0072\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9814e-05 - mse: 6.9814e-05 - mae: 0.0072\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9346e-05 - mse: 6.9346e-05 - mae: 0.0071\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8880e-05 - mse: 6.8880e-05 - mae: 0.0071\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.8415e-05 - mse: 6.8415e-05 - mae: 0.0071\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7953e-05 - mse: 6.7953e-05 - mae: 0.0071\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7490e-05 - mse: 6.7490e-05 - mae: 0.0071\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7037e-05 - mse: 6.7037e-05 - mae: 0.0070\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6582e-05 - mse: 6.6582e-05 - mae: 0.0070\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6134e-05 - mse: 6.6134e-05 - mae: 0.0070\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5688e-05 - mse: 6.5688e-05 - mae: 0.0070\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5245e-05 - mse: 6.5245e-05 - mae: 0.0069\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4804e-05 - mse: 6.4804e-05 - mae: 0.0069\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4365e-05 - mse: 6.4365e-05 - mae: 0.0069\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3929e-05 - mse: 6.3929e-05 - mae: 0.0069\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3499e-05 - mse: 6.3499e-05 - mae: 0.0068\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3066e-05 - mse: 6.3066e-05 - mae: 0.0068\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2645e-05 - mse: 6.2645e-05 - mae: 0.0068\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2218e-05 - mse: 6.2218e-05 - mae: 0.0068\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.1805e-05 - mse: 6.1805e-05 - mae: 0.0067\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.1384e-05 - mse: 6.1384e-05 - mae: 0.0067\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0973e-05 - mse: 6.0973e-05 - mae: 0.0067\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0558e-05 - mse: 6.0558e-05 - mae: 0.0067\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.0153e-05 - mse: 6.0153e-05 - mae: 0.0067\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.9740e-05 - mse: 5.9740e-05 - mae: 0.0066\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9341e-05 - mse: 5.9341e-05 - mae: 0.0066\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.8941e-05 - mse: 5.8941e-05 - mae: 0.0066\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.8542e-05 - mse: 5.8542e-05 - mae: 0.0066\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8146e-05 - mse: 5.8146e-05 - mae: 0.0065\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7754e-05 - mse: 5.7754e-05 - mae: 0.0065\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7365e-05 - mse: 5.7365e-05 - mae: 0.0065\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6980e-05 - mse: 5.6980e-05 - mae: 0.0065\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.6591e-05 - mse: 5.6591e-05 - mae: 0.0065\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6209e-05 - mse: 5.6209e-05 - mae: 0.0064\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5834e-05 - mse: 5.5834e-05 - mae: 0.0064\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5457e-05 - mse: 5.5457e-05 - mae: 0.0064\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5078e-05 - mse: 5.5078e-05 - mae: 0.0064\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4706e-05 - mse: 5.4706e-05 - mae: 0.0063\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4341e-05 - mse: 5.4341e-05 - mae: 0.0063\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3972e-05 - mse: 5.3972e-05 - mae: 0.0063\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3608e-05 - mse: 5.3608e-05 - mae: 0.0063\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3249e-05 - mse: 5.3249e-05 - mae: 0.0063\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2888e-05 - mse: 5.2888e-05 - mae: 0.0062\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2529e-05 - mse: 5.2529e-05 - mae: 0.0062\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2173e-05 - mse: 5.2173e-05 - mae: 0.0062\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1823e-05 - mse: 5.1823e-05 - mae: 0.0062\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1473e-05 - mse: 5.1473e-05 - mae: 0.0062\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1128e-05 - mse: 5.1128e-05 - mae: 0.0061\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0781e-05 - mse: 5.0781e-05 - mae: 0.0061\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0437e-05 - mse: 5.0437e-05 - mae: 0.0061\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0095e-05 - mse: 5.0095e-05 - mae: 0.0061\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.9760e-05 - mse: 4.9760e-05 - mae: 0.0061\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9428e-05 - mse: 4.9428e-05 - mae: 0.0060\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9090e-05 - mse: 4.9090e-05 - mae: 0.0060\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8758e-05 - mse: 4.8758e-05 - mae: 0.0060\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8429e-05 - mse: 4.8429e-05 - mae: 0.0060\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8103e-05 - mse: 4.8103e-05 - mae: 0.0060\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7779e-05 - mse: 4.7779e-05 - mae: 0.0059\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7458e-05 - mse: 4.7458e-05 - mae: 0.0059\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7138e-05 - mse: 4.7138e-05 - mae: 0.0059\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6815e-05 - mse: 4.6815e-05 - mae: 0.0059\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6499e-05 - mse: 4.6499e-05 - mae: 0.0059\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6185e-05 - mse: 4.6185e-05 - mae: 0.0058\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5876e-05 - mse: 4.5876e-05 - mae: 0.0058\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5570e-05 - mse: 4.5570e-05 - mae: 0.0058\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5260e-05 - mse: 4.5260e-05 - mae: 0.0058\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4953e-05 - mse: 4.4953e-05 - mae: 0.0058\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4650e-05 - mse: 4.4650e-05 - mae: 0.0057\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4349e-05 - mse: 4.4349e-05 - mae: 0.0057\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4046e-05 - mse: 4.4046e-05 - mae: 0.0057\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3752e-05 - mse: 4.3752e-05 - mae: 0.0057\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3454e-05 - mse: 4.3454e-05 - mae: 0.0057\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3160e-05 - mse: 4.3160e-05 - mae: 0.0056\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2874e-05 - mse: 4.2874e-05 - mae: 0.0056\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2582e-05 - mse: 4.2582e-05 - mae: 0.0056\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2296e-05 - mse: 4.2296e-05 - mae: 0.0056\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2008e-05 - mse: 4.2008e-05 - mae: 0.0056\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1727e-05 - mse: 4.1727e-05 - mae: 0.0055\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1443e-05 - mse: 4.1443e-05 - mae: 0.0055\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1164e-05 - mse: 4.1164e-05 - mae: 0.0055\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0887e-05 - mse: 4.0887e-05 - mae: 0.0055\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0607e-05 - mse: 4.0607e-05 - mae: 0.0055\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0336e-05 - mse: 4.0336e-05 - mae: 0.0055\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0065e-05 - mse: 4.0065e-05 - mae: 0.0054\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9791e-05 - mse: 3.9791e-05 - mae: 0.0054\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9526e-05 - mse: 3.9526e-05 - mae: 0.0054\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9259e-05 - mse: 3.9259e-05 - mae: 0.0054\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8994e-05 - mse: 3.8994e-05 - mae: 0.0054\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8727e-05 - mse: 3.8727e-05 - mae: 0.0053\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8468e-05 - mse: 3.8468e-05 - mae: 0.0053\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8207e-05 - mse: 3.8207e-05 - mae: 0.0053\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7951e-05 - mse: 3.7951e-05 - mae: 0.0053\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7694e-05 - mse: 3.7694e-05 - mae: 0.0053\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7442e-05 - mse: 3.7442e-05 - mae: 0.0053\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7187e-05 - mse: 3.7187e-05 - mae: 0.0052\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6935e-05 - mse: 3.6935e-05 - mae: 0.0052\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6689e-05 - mse: 3.6689e-05 - mae: 0.0052\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6441e-05 - mse: 3.6441e-05 - mae: 0.0052\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6194e-05 - mse: 3.6194e-05 - mae: 0.0052\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5948e-05 - mse: 3.5948e-05 - mae: 0.0051\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5705e-05 - mse: 3.5705e-05 - mae: 0.0051\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5464e-05 - mse: 3.5464e-05 - mae: 0.0051\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5221e-05 - mse: 3.5221e-05 - mae: 0.0051\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4987e-05 - mse: 3.4987e-05 - mae: 0.0051\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4752e-05 - mse: 3.4752e-05 - mae: 0.0051\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4519e-05 - mse: 3.4519e-05 - mae: 0.0050\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4283e-05 - mse: 3.4283e-05 - mae: 0.0050\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4054e-05 - mse: 3.4054e-05 - mae: 0.0050\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3821e-05 - mse: 3.3821e-05 - mae: 0.0050\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3595e-05 - mse: 3.3595e-05 - mae: 0.0050\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3365e-05 - mse: 3.3365e-05 - mae: 0.0050\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3141e-05 - mse: 3.3141e-05 - mae: 0.0049\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2918e-05 - mse: 3.2918e-05 - mae: 0.0049\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2696e-05 - mse: 3.2696e-05 - mae: 0.0049\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2478e-05 - mse: 3.2478e-05 - mae: 0.0049\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2255e-05 - mse: 3.2255e-05 - mae: 0.0049\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.2037e-05 - mse: 3.2037e-05 - mae: 0.0049\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1821e-05 - mse: 3.1821e-05 - mae: 0.0048\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1606e-05 - mse: 3.1606e-05 - mae: 0.0048\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1394e-05 - mse: 3.1394e-05 - mae: 0.0048\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1184e-05 - mse: 3.1184e-05 - mae: 0.0048\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0970e-05 - mse: 3.0970e-05 - mae: 0.0048\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0764e-05 - mse: 3.0764e-05 - mae: 0.0048\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0555e-05 - mse: 3.0555e-05 - mae: 0.0047\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0349e-05 - mse: 3.0349e-05 - mae: 0.0047\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0145e-05 - mse: 3.0145e-05 - mae: 0.0047\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9940e-05 - mse: 2.9940e-05 - mae: 0.0047\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9739e-05 - mse: 2.9739e-05 - mae: 0.0047\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9536e-05 - mse: 2.9536e-05 - mae: 0.0047\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9340e-05 - mse: 2.9340e-05 - mae: 0.0046\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9141e-05 - mse: 2.9141e-05 - mae: 0.0046\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8943e-05 - mse: 2.8943e-05 - mae: 0.0046\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8748e-05 - mse: 2.8748e-05 - mae: 0.0046\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8555e-05 - mse: 2.8555e-05 - mae: 0.0046\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8365e-05 - mse: 2.8365e-05 - mae: 0.0046\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8170e-05 - mse: 2.8170e-05 - mae: 0.0046\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7978e-05 - mse: 2.7978e-05 - mae: 0.0045\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7793e-05 - mse: 2.7793e-05 - mae: 0.0045\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7604e-05 - mse: 2.7604e-05 - mae: 0.0045\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7415e-05 - mse: 2.7415e-05 - mae: 0.0045\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7230e-05 - mse: 2.7230e-05 - mae: 0.0045\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7048e-05 - mse: 2.7048e-05 - mae: 0.0045\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6862e-05 - mse: 2.6862e-05 - mae: 0.0044\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6682e-05 - mse: 2.6682e-05 - mae: 0.0044\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6503e-05 - mse: 2.6503e-05 - mae: 0.0044\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6325e-05 - mse: 2.6325e-05 - mae: 0.0044\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6146e-05 - mse: 2.6146e-05 - mae: 0.0044\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5971e-05 - mse: 2.5971e-05 - mae: 0.0044\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5796e-05 - mse: 2.5796e-05 - mae: 0.0044\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5622e-05 - mse: 2.5622e-05 - mae: 0.0043\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5447e-05 - mse: 2.5447e-05 - mae: 0.0043\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.5278e-05 - mse: 2.5278e-05 - mae: 0.0043\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.5105e-05 - mse: 2.5105e-05 - mae: 0.0043\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4938e-05 - mse: 2.4938e-05 - mae: 0.0043\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4769e-05 - mse: 2.4769e-05 - mae: 0.0043\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4603e-05 - mse: 2.4603e-05 - mae: 0.0043\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4434e-05 - mse: 2.4434e-05 - mae: 0.0042\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4269e-05 - mse: 2.4269e-05 - mae: 0.0042\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4103e-05 - mse: 2.4103e-05 - mae: 0.0042\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.3943e-05 - mse: 2.3943e-05 - mae: 0.0042\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.3783e-05 - mse: 2.3783e-05 - mae: 0.0042\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3621e-05 - mse: 2.3621e-05 - mae: 0.0042\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3465e-05 - mse: 2.3465e-05 - mae: 0.0042\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3302e-05 - mse: 2.3302e-05 - mae: 0.0041\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3145e-05 - mse: 2.3145e-05 - mae: 0.0041\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2988e-05 - mse: 2.2988e-05 - mae: 0.0041\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2835e-05 - mse: 2.2835e-05 - mae: 0.0041\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2679e-05 - mse: 2.2679e-05 - mae: 0.0041\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2526e-05 - mse: 2.2526e-05 - mae: 0.0041\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2376e-05 - mse: 2.2376e-05 - mae: 0.0041\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2225e-05 - mse: 2.2225e-05 - mae: 0.0040\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2073e-05 - mse: 2.2073e-05 - mae: 0.0040\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1926e-05 - mse: 2.1926e-05 - mae: 0.0040\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1778e-05 - mse: 2.1778e-05 - mae: 0.0040\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1630e-05 - mse: 2.1630e-05 - mae: 0.0040\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1487e-05 - mse: 2.1487e-05 - mae: 0.0040\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1340e-05 - mse: 2.1340e-05 - mae: 0.0040\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1196e-05 - mse: 2.1196e-05 - mae: 0.0040\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1052e-05 - mse: 2.1052e-05 - mae: 0.0039\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0911e-05 - mse: 2.0911e-05 - mae: 0.0039\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0770e-05 - mse: 2.0770e-05 - mae: 0.0039\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0627e-05 - mse: 2.0627e-05 - mae: 0.0039\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0491e-05 - mse: 2.0491e-05 - mae: 0.0039\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0354e-05 - mse: 2.0354e-05 - mae: 0.0039\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0216e-05 - mse: 2.0216e-05 - mae: 0.0039\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0079e-05 - mse: 2.0079e-05 - mae: 0.0038\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9943e-05 - mse: 1.9943e-05 - mae: 0.0038\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9808e-05 - mse: 1.9808e-05 - mae: 0.0038\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9676e-05 - mse: 1.9676e-05 - mae: 0.0038\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9543e-05 - mse: 1.9543e-05 - mae: 0.0038\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9408e-05 - mse: 1.9408e-05 - mae: 0.0038\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9277e-05 - mse: 1.9277e-05 - mae: 0.0038\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9149e-05 - mse: 1.9149e-05 - mae: 0.0038\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9018e-05 - mse: 1.9018e-05 - mae: 0.0037\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8888e-05 - mse: 1.8888e-05 - mae: 0.0037\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8764e-05 - mse: 1.8764e-05 - mae: 0.0037\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8634e-05 - mse: 1.8634e-05 - mae: 0.0037\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8508e-05 - mse: 1.8508e-05 - mae: 0.0037\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8384e-05 - mse: 1.8384e-05 - mae: 0.0037\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8261e-05 - mse: 1.8261e-05 - mae: 0.0037\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8136e-05 - mse: 1.8136e-05 - mae: 0.0037\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8017e-05 - mse: 1.8017e-05 - mae: 0.0036\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7894e-05 - mse: 1.7894e-05 - mae: 0.0036\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.7772e-05 - mse: 1.7772e-05 - mae: 0.0036\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7651e-05 - mse: 1.7651e-05 - mae: 0.0036\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7532e-05 - mse: 1.7532e-05 - mae: 0.0036\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7416e-05 - mse: 1.7416e-05 - mae: 0.0036\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7300e-05 - mse: 1.7300e-05 - mae: 0.0036\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7183e-05 - mse: 1.7183e-05 - mae: 0.0036\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.7064e-05 - mse: 1.7064e-05 - mae: 0.0035\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6951e-05 - mse: 1.6951e-05 - mae: 0.0035\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6837e-05 - mse: 1.6837e-05 - mae: 0.0035\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6723e-05 - mse: 1.6723e-05 - mae: 0.0035\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6609e-05 - mse: 1.6609e-05 - mae: 0.0035\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6496e-05 - mse: 1.6496e-05 - mae: 0.0035\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6386e-05 - mse: 1.6386e-05 - mae: 0.0035\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.6273e-05 - mse: 1.6273e-05 - mae: 0.0035\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6164e-05 - mse: 1.6164e-05 - mae: 0.0035\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6057e-05 - mse: 1.6057e-05 - mae: 0.0034\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5947e-05 - mse: 1.5947e-05 - mae: 0.0034\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5842e-05 - mse: 1.5842e-05 - mae: 0.0034\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5733e-05 - mse: 1.5733e-05 - mae: 0.0034\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5626e-05 - mse: 1.5626e-05 - mae: 0.0034\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5522e-05 - mse: 1.5522e-05 - mae: 0.0034\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5417e-05 - mse: 1.5417e-05 - mae: 0.0034\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5313e-05 - mse: 1.5313e-05 - mae: 0.0034\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5208e-05 - mse: 1.5208e-05 - mae: 0.0033\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5106e-05 - mse: 1.5106e-05 - mae: 0.0033\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5004e-05 - mse: 1.5004e-05 - mae: 0.0033\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4902e-05 - mse: 1.4902e-05 - mae: 0.0033\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4803e-05 - mse: 1.4803e-05 - mae: 0.0033\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4703e-05 - mse: 1.4703e-05 - mae: 0.0033\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4603e-05 - mse: 1.4603e-05 - mae: 0.0033\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4504e-05 - mse: 1.4504e-05 - mae: 0.0033\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4408e-05 - mse: 1.4408e-05 - mae: 0.0033\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4311e-05 - mse: 1.4311e-05 - mae: 0.0032\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4215e-05 - mse: 1.4215e-05 - mae: 0.0032\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4120e-05 - mse: 1.4120e-05 - mae: 0.0032\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4021e-05 - mse: 1.4021e-05 - mae: 0.0032\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3928e-05 - mse: 1.3928e-05 - mae: 0.0032\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3833e-05 - mse: 1.3833e-05 - mae: 0.0032\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3742e-05 - mse: 1.3742e-05 - mae: 0.0032\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3650e-05 - mse: 1.3650e-05 - mae: 0.0032\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3556e-05 - mse: 1.3556e-05 - mae: 0.0032\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3465e-05 - mse: 1.3465e-05 - mae: 0.0031\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3374e-05 - mse: 1.3374e-05 - mae: 0.0031\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3283e-05 - mse: 1.3283e-05 - mae: 0.0031\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3191e-05 - mse: 1.3191e-05 - mae: 0.0031\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3104e-05 - mse: 1.3104e-05 - mae: 0.0031\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3017e-05 - mse: 1.3017e-05 - mae: 0.0031\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2928e-05 - mse: 1.2928e-05 - mae: 0.0031\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2842e-05 - mse: 1.2842e-05 - mae: 0.0031\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2753e-05 - mse: 1.2753e-05 - mae: 0.0031\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2668e-05 - mse: 1.2668e-05 - mae: 0.0031\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2582e-05 - mse: 1.2582e-05 - mae: 0.0030\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2496e-05 - mse: 1.2496e-05 - mae: 0.0030\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2412e-05 - mse: 1.2412e-05 - mae: 0.0030\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2329e-05 - mse: 1.2329e-05 - mae: 0.0030\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2245e-05 - mse: 1.2245e-05 - mae: 0.0030\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2164e-05 - mse: 1.2164e-05 - mae: 0.0030\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2080e-05 - mse: 1.2080e-05 - mae: 0.0030\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2000e-05 - mse: 1.2000e-05 - mae: 0.0030\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1919e-05 - mse: 1.1919e-05 - mae: 0.0030\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1837e-05 - mse: 1.1837e-05 - mae: 0.0030\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1758e-05 - mse: 1.1758e-05 - mae: 0.0029\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1679e-05 - mse: 1.1679e-05 - mae: 0.0029\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1601e-05 - mse: 1.1601e-05 - mae: 0.0029\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1523e-05 - mse: 1.1523e-05 - mae: 0.0029\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1444e-05 - mse: 1.1444e-05 - mae: 0.0029\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1367e-05 - mse: 1.1367e-05 - mae: 0.0029\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1291e-05 - mse: 1.1291e-05 - mae: 0.0029\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1213e-05 - mse: 1.1213e-05 - mae: 0.0029\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1138e-05 - mse: 1.1138e-05 - mae: 0.0029\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1062e-05 - mse: 1.1062e-05 - mae: 0.0029\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0986e-05 - mse: 1.0986e-05 - mae: 0.0028\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0914e-05 - mse: 1.0914e-05 - mae: 0.0028\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0841e-05 - mse: 1.0841e-05 - mae: 0.0028\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0769e-05 - mse: 1.0769e-05 - mae: 0.0028\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0693e-05 - mse: 1.0693e-05 - mae: 0.0028\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0622e-05 - mse: 1.0622e-05 - mae: 0.0028\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0551e-05 - mse: 1.0551e-05 - mae: 0.0028\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0479e-05 - mse: 1.0479e-05 - mae: 0.0028\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0408e-05 - mse: 1.0408e-05 - mae: 0.0028\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0338e-05 - mse: 1.0338e-05 - mae: 0.0028\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0270e-05 - mse: 1.0270e-05 - mae: 0.0028\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0200e-05 - mse: 1.0200e-05 - mae: 0.0027\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0131e-05 - mse: 1.0131e-05 - mae: 0.0027\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0063e-05 - mse: 1.0063e-05 - mae: 0.0027\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9946e-06 - mse: 9.9946e-06 - mae: 0.0027\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.9271e-06 - mse: 9.9271e-06 - mae: 0.0027\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8612e-06 - mse: 9.8612e-06 - mae: 0.0027\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7921e-06 - mse: 9.7921e-06 - mae: 0.0027\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7259e-06 - mse: 9.7259e-06 - mae: 0.0027\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6610e-06 - mse: 9.6610e-06 - mae: 0.0027\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5962e-06 - mse: 9.5962e-06 - mae: 0.0027\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.5326e-06 - mse: 9.5326e-06 - mae: 0.0027\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 9.4666e-06 - mse: 9.4666e-06 - mae: 0.0026\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4041e-06 - mse: 9.4041e-06 - mae: 0.0026\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3374e-06 - mse: 9.3374e-06 - mae: 0.0026\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2769e-06 - mse: 9.2769e-06 - mae: 0.0026\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.2137e-06 - mse: 9.2137e-06 - mae: 0.0026\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.1519e-06 - mse: 9.1519e-06 - mae: 0.0026\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.0890e-06 - mse: 9.0890e-06 - mae: 0.0026\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.0282e-06 - mse: 9.0282e-06 - mae: 0.0026\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9666e-06 - mse: 8.9666e-06 - mae: 0.0026\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.9081e-06 - mse: 8.9081e-06 - mae: 0.0026\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8481e-06 - mse: 8.8481e-06 - mae: 0.0026\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7880e-06 - mse: 8.7880e-06 - mae: 0.0025\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7270e-06 - mse: 8.7270e-06 - mae: 0.0025\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6690e-06 - mse: 8.6690e-06 - mae: 0.0025\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.6103e-06 - mse: 8.6103e-06 - mae: 0.0025\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5542e-06 - mse: 8.5542e-06 - mae: 0.0025\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4946e-06 - mse: 8.4946e-06 - mae: 0.0025\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4377e-06 - mse: 8.4377e-06 - mae: 0.0025\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3802e-06 - mse: 8.3802e-06 - mae: 0.0025\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3229e-06 - mse: 8.3229e-06 - mae: 0.0025\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.2674e-06 - mse: 8.2674e-06 - mae: 0.0025\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2117e-06 - mse: 8.2117e-06 - mae: 0.0025\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1565e-06 - mse: 8.1565e-06 - mae: 0.0025\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1027e-06 - mse: 8.1027e-06 - mae: 0.0024\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.0471e-06 - mse: 8.0471e-06 - mae: 0.0024\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9938e-06 - mse: 7.9938e-06 - mae: 0.0024\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9390e-06 - mse: 7.9390e-06 - mae: 0.0024\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8864e-06 - mse: 7.8864e-06 - mae: 0.0024\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.8321e-06 - mse: 7.8321e-06 - mae: 0.0024\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7799e-06 - mse: 7.7799e-06 - mae: 0.0024\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7271e-06 - mse: 7.7271e-06 - mae: 0.0024\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6742e-06 - mse: 7.6742e-06 - mae: 0.0024\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6230e-06 - mse: 7.6230e-06 - mae: 0.0024\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5713e-06 - mse: 7.5713e-06 - mae: 0.0024\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5213e-06 - mse: 7.5213e-06 - mae: 0.0024\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4690e-06 - mse: 7.4690e-06 - mae: 0.0023\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4189e-06 - mse: 7.4189e-06 - mae: 0.0023\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3690e-06 - mse: 7.3690e-06 - mae: 0.0023\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3178e-06 - mse: 7.3178e-06 - mae: 0.0023\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2697e-06 - mse: 7.2697e-06 - mae: 0.0023\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2221e-06 - mse: 7.2221e-06 - mae: 0.0023\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1720e-06 - mse: 7.1720e-06 - mae: 0.0023\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1249e-06 - mse: 7.1249e-06 - mae: 0.0023\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0755e-06 - mse: 7.0755e-06 - mae: 0.0023\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0283e-06 - mse: 7.0283e-06 - mae: 0.0023\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9810e-06 - mse: 6.9810e-06 - mae: 0.0023\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9338e-06 - mse: 6.9338e-06 - mae: 0.0023\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8865e-06 - mse: 6.8865e-06 - mae: 0.0023\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.8402e-06 - mse: 6.8402e-06 - mae: 0.0022\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7944e-06 - mse: 6.7944e-06 - mae: 0.0022\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7489e-06 - mse: 6.7489e-06 - mae: 0.0022\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7035e-06 - mse: 6.7035e-06 - mae: 0.0022\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6568e-06 - mse: 6.6568e-06 - mae: 0.0022\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6122e-06 - mse: 6.6122e-06 - mae: 0.0022\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5686e-06 - mse: 6.5686e-06 - mae: 0.0022\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5230e-06 - mse: 6.5230e-06 - mae: 0.0022\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4797e-06 - mse: 6.4797e-06 - mae: 0.0022\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4356e-06 - mse: 6.4356e-06 - mae: 0.0022\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.3916e-06 - mse: 6.3916e-06 - mae: 0.0022\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.3507e-06 - mse: 6.3507e-06 - mae: 0.0022\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3053e-06 - mse: 6.3053e-06 - mae: 0.0022\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2626e-06 - mse: 6.2626e-06 - mae: 0.0021\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2205e-06 - mse: 6.2205e-06 - mae: 0.0021\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1783e-06 - mse: 6.1783e-06 - mae: 0.0021\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1368e-06 - mse: 6.1368e-06 - mae: 0.0021\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0960e-06 - mse: 6.0960e-06 - mae: 0.0021\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0546e-06 - mse: 6.0546e-06 - mae: 0.0021\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0144e-06 - mse: 6.0144e-06 - mae: 0.0021\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9734e-06 - mse: 5.9734e-06 - mae: 0.0021\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9326e-06 - mse: 5.9326e-06 - mae: 0.0021\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8935e-06 - mse: 5.8935e-06 - mae: 0.0021\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8520e-06 - mse: 5.8520e-06 - mae: 0.0021\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.8141e-06 - mse: 5.8141e-06 - mae: 0.0021\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7744e-06 - mse: 5.7744e-06 - mae: 0.0021\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7348e-06 - mse: 5.7348e-06 - mae: 0.0021\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6956e-06 - mse: 5.6956e-06 - mae: 0.0020\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6595e-06 - mse: 5.6595e-06 - mae: 0.0020\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6205e-06 - mse: 5.6205e-06 - mae: 0.0020\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5826e-06 - mse: 5.5826e-06 - mae: 0.0020\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5440e-06 - mse: 5.5440e-06 - mae: 0.0020\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5074e-06 - mse: 5.5074e-06 - mae: 0.0020\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4694e-06 - mse: 5.4694e-06 - mae: 0.0020\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.4336e-06 - mse: 5.4336e-06 - mae: 0.0020\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3966e-06 - mse: 5.3966e-06 - mae: 0.0020\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3591e-06 - mse: 5.3591e-06 - mae: 0.0020\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3240e-06 - mse: 5.3240e-06 - mae: 0.0020\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2887e-06 - mse: 5.2887e-06 - mae: 0.0020\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2520e-06 - mse: 5.2520e-06 - mae: 0.0020\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2165e-06 - mse: 5.2165e-06 - mae: 0.0020\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1819e-06 - mse: 5.1819e-06 - mae: 0.0020\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1467e-06 - mse: 5.1467e-06 - mae: 0.0019\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.1135e-06 - mse: 5.1135e-06 - mae: 0.0019\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.0766e-06 - mse: 5.0766e-06 - mae: 0.0019\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0437e-06 - mse: 5.0437e-06 - mae: 0.0019\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0090e-06 - mse: 5.0090e-06 - mae: 0.0019\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9745e-06 - mse: 4.9745e-06 - mae: 0.0019\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9412e-06 - mse: 4.9412e-06 - mae: 0.0019\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9082e-06 - mse: 4.9082e-06 - mae: 0.0019\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8754e-06 - mse: 4.8754e-06 - mae: 0.0019\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8415e-06 - mse: 4.8415e-06 - mae: 0.0019\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8096e-06 - mse: 4.8096e-06 - mae: 0.0019\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7776e-06 - mse: 4.7776e-06 - mae: 0.0019\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7444e-06 - mse: 4.7444e-06 - mae: 0.0019\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7133e-06 - mse: 4.7133e-06 - mae: 0.0019\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.6808e-06 - mse: 4.6808e-06 - mae: 0.0019\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6499e-06 - mse: 4.6499e-06 - mae: 0.0019\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6177e-06 - mse: 4.6177e-06 - mae: 0.0018\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5874e-06 - mse: 4.5874e-06 - mae: 0.0018\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5560e-06 - mse: 4.5560e-06 - mae: 0.0018\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5245e-06 - mse: 4.5245e-06 - mae: 0.0018\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.4949e-06 - mse: 4.4949e-06 - mae: 0.0018\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4643e-06 - mse: 4.4643e-06 - mae: 0.0018\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4344e-06 - mse: 4.4344e-06 - mae: 0.0018\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4042e-06 - mse: 4.4042e-06 - mae: 0.0018\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3749e-06 - mse: 4.3749e-06 - mae: 0.0018\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.3446e-06 - mse: 4.3446e-06 - mae: 0.0018\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3155e-06 - mse: 4.3155e-06 - mae: 0.0018\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2868e-06 - mse: 4.2868e-06 - mae: 0.0018\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2580e-06 - mse: 4.2580e-06 - mae: 0.0018\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2284e-06 - mse: 4.2284e-06 - mae: 0.0018\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2007e-06 - mse: 4.2007e-06 - mae: 0.0018\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.1729e-06 - mse: 4.1729e-06 - mae: 0.0018\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1430e-06 - mse: 4.1430e-06 - mae: 0.0017\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1160e-06 - mse: 4.1160e-06 - mae: 0.0017\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0875e-06 - mse: 4.0875e-06 - mae: 0.0017\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 4.0606e-06 - mse: 4.0606e-06 - mae: 0.0017\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0334e-06 - mse: 4.0334e-06 - mae: 0.0017\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0055e-06 - mse: 4.0055e-06 - mae: 0.0017\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9802e-06 - mse: 3.9802e-06 - mae: 0.0017\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9526e-06 - mse: 3.9526e-06 - mae: 0.0017\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9259e-06 - mse: 3.9259e-06 - mae: 0.0017\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8978e-06 - mse: 3.8978e-06 - mae: 0.0017\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8739e-06 - mse: 3.8739e-06 - mae: 0.0017\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8477e-06 - mse: 3.8477e-06 - mae: 0.0017\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8200e-06 - mse: 3.8200e-06 - mae: 0.0017\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7947e-06 - mse: 3.7947e-06 - mae: 0.0017\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7699e-06 - mse: 3.7699e-06 - mae: 0.0017\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7441e-06 - mse: 3.7441e-06 - mae: 0.0017\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7188e-06 - mse: 3.7188e-06 - mae: 0.0017\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6928e-06 - mse: 3.6928e-06 - mae: 0.0016\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6683e-06 - mse: 3.6683e-06 - mae: 0.0016\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6439e-06 - mse: 3.6439e-06 - mae: 0.0016\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6202e-06 - mse: 3.6202e-06 - mae: 0.0016\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5948e-06 - mse: 3.5948e-06 - mae: 0.0016\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5698e-06 - mse: 3.5698e-06 - mae: 0.0016\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5467e-06 - mse: 3.5467e-06 - mae: 0.0016\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5223e-06 - mse: 3.5223e-06 - mae: 0.0016\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4982e-06 - mse: 3.4982e-06 - mae: 0.0016\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.4747e-06 - mse: 3.4747e-06 - mae: 0.0016\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4508e-06 - mse: 3.4508e-06 - mae: 0.0016\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4290e-06 - mse: 3.4290e-06 - mae: 0.0016\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4046e-06 - mse: 3.4046e-06 - mae: 0.0016\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3817e-06 - mse: 3.3817e-06 - mae: 0.0016\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3604e-06 - mse: 3.3604e-06 - mae: 0.0016\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3375e-06 - mse: 3.3375e-06 - mae: 0.0016\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3151e-06 - mse: 3.3151e-06 - mae: 0.0016\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2913e-06 - mse: 3.2913e-06 - mae: 0.0016\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2688e-06 - mse: 3.2688e-06 - mae: 0.0016\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2472e-06 - mse: 3.2472e-06 - mae: 0.0015\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2249e-06 - mse: 3.2249e-06 - mae: 0.0015\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2030e-06 - mse: 3.2030e-06 - mae: 0.0015\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1822e-06 - mse: 3.1822e-06 - mae: 0.0015\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1604e-06 - mse: 3.1604e-06 - mae: 0.0015\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1388e-06 - mse: 3.1388e-06 - mae: 0.0015\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1188e-06 - mse: 3.1188e-06 - mae: 0.0015\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0971e-06 - mse: 3.0971e-06 - mae: 0.0015\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0758e-06 - mse: 3.0758e-06 - mae: 0.0015\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0551e-06 - mse: 3.0551e-06 - mae: 0.0015\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0352e-06 - mse: 3.0352e-06 - mae: 0.0015\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0147e-06 - mse: 3.0147e-06 - mae: 0.0015\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9940e-06 - mse: 2.9940e-06 - mae: 0.0015\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9733e-06 - mse: 2.9733e-06 - mae: 0.0015\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9532e-06 - mse: 2.9532e-06 - mae: 0.0015\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9343e-06 - mse: 2.9343e-06 - mae: 0.0015\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9144e-06 - mse: 2.9144e-06 - mae: 0.0015\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8943e-06 - mse: 2.8943e-06 - mae: 0.0015\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8749e-06 - mse: 2.8749e-06 - mae: 0.0015\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8556e-06 - mse: 2.8556e-06 - mae: 0.0015\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8356e-06 - mse: 2.8356e-06 - mae: 0.0014\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8171e-06 - mse: 2.8171e-06 - mae: 0.0014\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7980e-06 - mse: 2.7980e-06 - mae: 0.0014\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7797e-06 - mse: 2.7797e-06 - mae: 0.0014\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7600e-06 - mse: 2.7600e-06 - mae: 0.0014\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7422e-06 - mse: 2.7422e-06 - mae: 0.0014\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7240e-06 - mse: 2.7240e-06 - mae: 0.0014\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7049e-06 - mse: 2.7049e-06 - mae: 0.0014\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6870e-06 - mse: 2.6870e-06 - mae: 0.0014\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6687e-06 - mse: 2.6687e-06 - mae: 0.0014\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6500e-06 - mse: 2.6500e-06 - mae: 0.0014\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6328e-06 - mse: 2.6328e-06 - mae: 0.0014\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6148e-06 - mse: 2.6148e-06 - mae: 0.0014\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5969e-06 - mse: 2.5969e-06 - mae: 0.0014\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5798e-06 - mse: 2.5798e-06 - mae: 0.0014\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5623e-06 - mse: 2.5623e-06 - mae: 0.0014\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5445e-06 - mse: 2.5445e-06 - mae: 0.0014\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5280e-06 - mse: 2.5280e-06 - mae: 0.0014\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5106e-06 - mse: 2.5106e-06 - mae: 0.0014\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.4943e-06 - mse: 2.4943e-06 - mae: 0.0014\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4771e-06 - mse: 2.4771e-06 - mae: 0.0014\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.4606e-06 - mse: 2.4606e-06 - mae: 0.0013\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4431e-06 - mse: 2.4431e-06 - mae: 0.0013\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4270e-06 - mse: 2.4270e-06 - mae: 0.0013\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4108e-06 - mse: 2.4108e-06 - mae: 0.0013\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3946e-06 - mse: 2.3946e-06 - mae: 0.0013\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3788e-06 - mse: 2.3788e-06 - mae: 0.0013\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3617e-06 - mse: 2.3617e-06 - mae: 0.0013\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3467e-06 - mse: 2.3467e-06 - mae: 0.0013\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3309e-06 - mse: 2.3309e-06 - mae: 0.0013\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3148e-06 - mse: 2.3148e-06 - mae: 0.0013\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2997e-06 - mse: 2.2997e-06 - mae: 0.0013\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2830e-06 - mse: 2.2830e-06 - mae: 0.0013\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2687e-06 - mse: 2.2687e-06 - mae: 0.0013\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2524e-06 - mse: 2.2524e-06 - mae: 0.0013\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2379e-06 - mse: 2.2379e-06 - mae: 0.0013\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2227e-06 - mse: 2.2227e-06 - mae: 0.0013\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2082e-06 - mse: 2.2082e-06 - mae: 0.0013\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1925e-06 - mse: 2.1925e-06 - mae: 0.0013\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1780e-06 - mse: 2.1780e-06 - mae: 0.0013\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1639e-06 - mse: 2.1639e-06 - mae: 0.0013\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1486e-06 - mse: 2.1486e-06 - mae: 0.0013\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1340e-06 - mse: 2.1340e-06 - mae: 0.0013\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1196e-06 - mse: 2.1196e-06 - mae: 0.0012\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1053e-06 - mse: 2.1053e-06 - mae: 0.0012\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0911e-06 - mse: 2.0911e-06 - mae: 0.0012\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0773e-06 - mse: 2.0773e-06 - mae: 0.0012\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.0629e-06 - mse: 2.0629e-06 - mae: 0.0012\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0496e-06 - mse: 2.0496e-06 - mae: 0.0012\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0361e-06 - mse: 2.0361e-06 - mae: 0.0012\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0215e-06 - mse: 2.0215e-06 - mae: 0.0012\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0083e-06 - mse: 2.0083e-06 - mae: 0.0012\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9950e-06 - mse: 1.9950e-06 - mae: 0.0012\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9807e-06 - mse: 1.9807e-06 - mae: 0.0012\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9675e-06 - mse: 1.9675e-06 - mae: 0.0012\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9545e-06 - mse: 1.9545e-06 - mae: 0.0012\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9419e-06 - mse: 1.9419e-06 - mae: 0.0012\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9292e-06 - mse: 1.9292e-06 - mae: 0.0012\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9152e-06 - mse: 1.9152e-06 - mae: 0.0012\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9029e-06 - mse: 1.9029e-06 - mae: 0.0012\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8892e-06 - mse: 1.8892e-06 - mae: 0.0012\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8768e-06 - mse: 1.8768e-06 - mae: 0.0012\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8637e-06 - mse: 1.8637e-06 - mae: 0.0012\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8510e-06 - mse: 1.8510e-06 - mae: 0.0012\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8395e-06 - mse: 1.8395e-06 - mae: 0.0012\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8269e-06 - mse: 1.8269e-06 - mae: 0.0012\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8142e-06 - mse: 1.8142e-06 - mae: 0.0012\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8013e-06 - mse: 1.8013e-06 - mae: 0.0012\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7893e-06 - mse: 1.7893e-06 - mae: 0.0011\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7783e-06 - mse: 1.7783e-06 - mae: 0.0011\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7658e-06 - mse: 1.7658e-06 - mae: 0.0011\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7539e-06 - mse: 1.7539e-06 - mae: 0.0011\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7421e-06 - mse: 1.7421e-06 - mae: 0.0011\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7303e-06 - mse: 1.7303e-06 - mae: 0.0011\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7190e-06 - mse: 1.7190e-06 - mae: 0.0011\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7076e-06 - mse: 1.7076e-06 - mae: 0.0011\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6959e-06 - mse: 1.6959e-06 - mae: 0.0011\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6848e-06 - mse: 1.6848e-06 - mae: 0.0011\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6735e-06 - mse: 1.6735e-06 - mae: 0.0011\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6614e-06 - mse: 1.6614e-06 - mae: 0.0011\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6502e-06 - mse: 1.6502e-06 - mae: 0.0011\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6392e-06 - mse: 1.6392e-06 - mae: 0.0011\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6284e-06 - mse: 1.6284e-06 - mae: 0.0011\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6177e-06 - mse: 1.6177e-06 - mae: 0.0011\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6067e-06 - mse: 1.6067e-06 - mae: 0.0011\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5956e-06 - mse: 1.5956e-06 - mae: 0.0011\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5852e-06 - mse: 1.5852e-06 - mae: 0.0011\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5738e-06 - mse: 1.5738e-06 - mae: 0.0011\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5629e-06 - mse: 1.5629e-06 - mae: 0.0011\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5529e-06 - mse: 1.5529e-06 - mae: 0.0011\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5430e-06 - mse: 1.5430e-06 - mae: 0.0011\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5316e-06 - mse: 1.5316e-06 - mae: 0.0011\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5220e-06 - mse: 1.5220e-06 - mae: 0.0011\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5114e-06 - mse: 1.5114e-06 - mae: 0.0011\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5012e-06 - mse: 1.5012e-06 - mae: 0.0011\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4908e-06 - mse: 1.4908e-06 - mae: 0.0010\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4806e-06 - mse: 1.4806e-06 - mae: 0.0010\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4716e-06 - mse: 1.4716e-06 - mae: 0.0010\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4613e-06 - mse: 1.4613e-06 - mae: 0.0010\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4511e-06 - mse: 1.4511e-06 - mae: 0.0010\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4424e-06 - mse: 1.4424e-06 - mae: 0.0010\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4323e-06 - mse: 1.4323e-06 - mae: 0.0010\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4218e-06 - mse: 1.4218e-06 - mae: 0.0010\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.4121e-06 - mse: 1.4121e-06 - mae: 0.0010\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4025e-06 - mse: 1.4025e-06 - mae: 0.0010\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3938e-06 - mse: 1.3938e-06 - mae: 0.0010\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3843e-06 - mse: 1.3843e-06 - mae: 0.0010\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3751e-06 - mse: 1.3751e-06 - mae: 0.0010\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3658e-06 - mse: 1.3658e-06 - mae: 0.0010\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3565e-06 - mse: 1.3565e-06 - mae: 9.9974e-04\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3478e-06 - mse: 1.3478e-06 - mae: 9.9640e-04\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3376e-06 - mse: 1.3376e-06 - mae: 9.9249e-04\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3294e-06 - mse: 1.3294e-06 - mae: 9.8972e-04\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3202e-06 - mse: 1.3202e-06 - mae: 9.8610e-04\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3118e-06 - mse: 1.3118e-06 - mae: 9.8314e-04\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3028e-06 - mse: 1.3028e-06 - mae: 9.7971e-04\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2935e-06 - mse: 1.2935e-06 - mae: 9.7618e-04\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2852e-06 - mse: 1.2852e-06 - mae: 9.7303e-04\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2761e-06 - mse: 1.2761e-06 - mae: 9.6970e-04\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2668e-06 - mse: 1.2668e-06 - mae: 9.6598e-04\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2592e-06 - mse: 1.2592e-06 - mae: 9.6321e-04\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2510e-06 - mse: 1.2510e-06 - mae: 9.6025e-04\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2419e-06 - mse: 1.2419e-06 - mae: 9.5654e-04\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2339e-06 - mse: 1.2339e-06 - mae: 9.5348e-04\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2254e-06 - mse: 1.2254e-06 - mae: 9.5024e-04\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2166e-06 - mse: 1.2166e-06 - mae: 9.4681e-04\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2092e-06 - mse: 1.2092e-06 - mae: 9.4404e-04\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2007e-06 - mse: 1.2007e-06 - mae: 9.4061e-04\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1930e-06 - mse: 1.1930e-06 - mae: 9.3775e-04\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1851e-06 - mse: 1.1851e-06 - mae: 9.3451e-04\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1766e-06 - mse: 1.1766e-06 - mae: 9.3126e-04\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1688e-06 - mse: 1.1688e-06 - mae: 9.2802e-04\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1604e-06 - mse: 1.1604e-06 - mae: 9.2478e-04\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1526e-06 - mse: 1.1526e-06 - mae: 9.2154e-04\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1454e-06 - mse: 1.1454e-06 - mae: 9.1877e-04\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1375e-06 - mse: 1.1375e-06 - mae: 9.1553e-04\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1296e-06 - mse: 1.1296e-06 - mae: 9.1238e-04\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1218e-06 - mse: 1.1218e-06 - mae: 9.0923e-04\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1149e-06 - mse: 1.1149e-06 - mae: 9.0637e-04\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1075e-06 - mse: 1.1075e-06 - mae: 9.0322e-04\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0999e-06 - mse: 1.0999e-06 - mae: 9.0017e-04\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0918e-06 - mse: 1.0918e-06 - mae: 8.9664e-04\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0853e-06 - mse: 1.0853e-06 - mae: 8.9417e-04\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0767e-06 - mse: 1.0767e-06 - mae: 8.9045e-04\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0697e-06 - mse: 1.0697e-06 - mae: 8.8768e-04\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0630e-06 - mse: 1.0630e-06 - mae: 8.8501e-04\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0559e-06 - mse: 1.0559e-06 - mae: 8.8205e-04\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0488e-06 - mse: 1.0488e-06 - mae: 8.7910e-04\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0418e-06 - mse: 1.0418e-06 - mae: 8.7614e-04\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0344e-06 - mse: 1.0344e-06 - mae: 8.7290e-04\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0275e-06 - mse: 1.0275e-06 - mae: 8.7013e-04\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0206e-06 - mse: 1.0206e-06 - mae: 8.6718e-04\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0141e-06 - mse: 1.0141e-06 - mae: 8.6451e-04\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0070e-06 - mse: 1.0070e-06 - mae: 8.6136e-04\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0006e-06 - mse: 1.0006e-06 - mae: 8.5869e-04\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9347e-07 - mse: 9.9347e-07 - mae: 8.5564e-04\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.8640e-07 - mse: 9.8640e-07 - mae: 8.5249e-04\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.8005e-07 - mse: 9.8005e-07 - mae: 8.4982e-04\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7391e-07 - mse: 9.7391e-07 - mae: 8.4724e-04\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6691e-07 - mse: 9.6691e-07 - mae: 8.4419e-04\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.6082e-07 - mse: 9.6082e-07 - mae: 8.4162e-04\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5377e-07 - mse: 9.5377e-07 - mae: 8.3828e-04\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4745e-07 - mse: 9.4745e-07 - mae: 8.3561e-04\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4142e-07 - mse: 9.4142e-07 - mae: 8.3303e-04\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3471e-07 - mse: 9.3471e-07 - mae: 8.2989e-04\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2824e-07 - mse: 9.2824e-07 - mae: 8.2703e-04\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2208e-07 - mse: 9.2208e-07 - mae: 8.2436e-04\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1597e-07 - mse: 9.1597e-07 - mae: 8.2159e-04\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1015e-07 - mse: 9.1015e-07 - mae: 8.1902e-04\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.0362e-07 - mse: 9.0362e-07 - mae: 8.1596e-04\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9753e-07 - mse: 8.9753e-07 - mae: 8.1329e-04\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.9187e-07 - mse: 8.9187e-07 - mae: 8.1062e-04\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8541e-07 - mse: 8.8541e-07 - mae: 8.0757e-04\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7923e-07 - mse: 8.7923e-07 - mae: 8.0471e-04\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7348e-07 - mse: 8.7348e-07 - mae: 8.0214e-04\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6753e-07 - mse: 8.6753e-07 - mae: 7.9937e-04\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.6157e-07 - mse: 8.6157e-07 - mae: 7.9670e-04\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.5630e-07 - mse: 8.5630e-07 - mae: 7.9432e-04\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5023e-07 - mse: 8.5023e-07 - mae: 7.9145e-04\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.4476e-07 - mse: 8.4476e-07 - mae: 7.8897e-04\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3882e-07 - mse: 8.3882e-07 - mae: 7.8602e-04\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3276e-07 - mse: 8.3276e-07 - mae: 7.8316e-04\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2721e-07 - mse: 8.2721e-07 - mae: 7.8058e-04\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.2182e-07 - mse: 8.2182e-07 - mae: 7.7810e-04\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1649e-07 - mse: 8.1649e-07 - mae: 7.7562e-04\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1051e-07 - mse: 8.1051e-07 - mae: 7.7276e-04\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.0522e-07 - mse: 8.0522e-07 - mae: 7.7028e-04\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9989e-07 - mse: 7.9989e-07 - mae: 7.6780e-04\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9471e-07 - mse: 7.9471e-07 - mae: 7.6523e-04\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.8943e-07 - mse: 7.8943e-07 - mae: 7.6275e-04\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.8421e-07 - mse: 7.8421e-07 - mae: 7.6027e-04\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7839e-07 - mse: 7.7839e-07 - mae: 7.5741e-04\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7316e-07 - mse: 7.7316e-07 - mae: 7.5493e-04\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6845e-07 - mse: 7.6845e-07 - mae: 7.5264e-04\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6315e-07 - mse: 7.6315e-07 - mae: 7.4997e-04\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5789e-07 - mse: 7.5789e-07 - mae: 7.4730e-04\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5226e-07 - mse: 7.5226e-07 - mae: 7.4463e-04\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4761e-07 - mse: 7.4761e-07 - mae: 7.4234e-04\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4238e-07 - mse: 7.4238e-07 - mae: 7.3967e-04\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3777e-07 - mse: 7.3777e-07 - mae: 7.3738e-04\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3317e-07 - mse: 7.3317e-07 - mae: 7.3509e-04\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2755e-07 - mse: 7.2755e-07 - mae: 7.3223e-04\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2285e-07 - mse: 7.2285e-07 - mae: 7.2975e-04\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1792e-07 - mse: 7.1792e-07 - mae: 7.2746e-04\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1318e-07 - mse: 7.1318e-07 - mae: 7.2479e-04\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0828e-07 - mse: 7.0828e-07 - mae: 7.2250e-04\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0357e-07 - mse: 7.0357e-07 - mae: 7.1983e-04\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9870e-07 - mse: 6.9870e-07 - mae: 7.1754e-04\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9402e-07 - mse: 6.9402e-07 - mae: 7.1487e-04\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8911e-07 - mse: 6.8911e-07 - mae: 7.1239e-04\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.8446e-07 - mse: 6.8446e-07 - mae: 7.1001e-04\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8019e-07 - mse: 6.8019e-07 - mae: 7.0782e-04\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7569e-07 - mse: 6.7569e-07 - mae: 7.0562e-04\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7072e-07 - mse: 6.7072e-07 - mae: 7.0295e-04\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6629e-07 - mse: 6.6629e-07 - mae: 7.0066e-04\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6218e-07 - mse: 6.6218e-07 - mae: 6.9847e-04\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5731e-07 - mse: 6.5731e-07 - mae: 6.9580e-04\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5292e-07 - mse: 6.5292e-07 - mae: 6.9351e-04\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4855e-07 - mse: 6.4855e-07 - mae: 6.9122e-04\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4403e-07 - mse: 6.4403e-07 - mae: 6.8884e-04\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3965e-07 - mse: 6.3965e-07 - mae: 6.8636e-04\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3544e-07 - mse: 6.3544e-07 - mae: 6.8426e-04\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3101e-07 - mse: 6.3101e-07 - mae: 6.8188e-04\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2697e-07 - mse: 6.2697e-07 - mae: 6.7968e-04\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2281e-07 - mse: 6.2281e-07 - mae: 6.7759e-04\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1903e-07 - mse: 6.1903e-07 - mae: 6.7549e-04\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.1424e-07 - mse: 6.1424e-07 - mae: 6.7282e-04\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1029e-07 - mse: 6.1029e-07 - mae: 6.7062e-04\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0607e-07 - mse: 6.0607e-07 - mae: 6.6833e-04\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0215e-07 - mse: 6.0215e-07 - mae: 6.6614e-04\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9824e-07 - mse: 5.9824e-07 - mae: 6.6395e-04\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9364e-07 - mse: 5.9364e-07 - mae: 6.6147e-04\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8977e-07 - mse: 5.8977e-07 - mae: 6.5928e-04\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8613e-07 - mse: 5.8613e-07 - mae: 6.5737e-04\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8203e-07 - mse: 5.8203e-07 - mae: 6.5508e-04\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7819e-07 - mse: 5.7819e-07 - mae: 6.5289e-04\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7395e-07 - mse: 5.7395e-07 - mae: 6.5041e-04\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7014e-07 - mse: 5.7014e-07 - mae: 6.4821e-04\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6660e-07 - mse: 5.6660e-07 - mae: 6.4631e-04\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6281e-07 - mse: 5.6281e-07 - mae: 6.4411e-04\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5863e-07 - mse: 5.5863e-07 - mae: 6.4163e-04\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5498e-07 - mse: 5.5498e-07 - mae: 6.3963e-04\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5138e-07 - mse: 5.5138e-07 - mae: 6.3753e-04\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4803e-07 - mse: 5.4803e-07 - mae: 6.3553e-04\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4379e-07 - mse: 5.4379e-07 - mae: 6.3295e-04\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4023e-07 - mse: 5.4023e-07 - mae: 6.3086e-04\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3691e-07 - mse: 5.3691e-07 - mae: 6.2885e-04\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3294e-07 - mse: 5.3294e-07 - mae: 6.2656e-04\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2941e-07 - mse: 5.2941e-07 - mae: 6.2447e-04\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2609e-07 - mse: 5.2609e-07 - mae: 6.2256e-04\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2223e-07 - mse: 5.2223e-07 - mae: 6.2017e-04\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1855e-07 - mse: 5.1855e-07 - mae: 6.1798e-04\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1516e-07 - mse: 5.1516e-07 - mae: 6.1588e-04\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1139e-07 - mse: 5.1139e-07 - mae: 6.1378e-04\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0830e-07 - mse: 5.0830e-07 - mae: 6.1188e-04\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0519e-07 - mse: 5.0519e-07 - mae: 6.1007e-04\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0158e-07 - mse: 5.0158e-07 - mae: 6.0787e-04\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9794e-07 - mse: 4.9794e-07 - mae: 6.0549e-04\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9494e-07 - mse: 4.9494e-07 - mae: 6.0387e-04\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9150e-07 - mse: 4.9150e-07 - mae: 6.0177e-04\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8796e-07 - mse: 4.8796e-07 - mae: 5.9958e-04\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8441e-07 - mse: 4.8441e-07 - mae: 5.9738e-04\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.8123e-07 - mse: 4.8123e-07 - mae: 5.9538e-04\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7832e-07 - mse: 4.7832e-07 - mae: 5.9376e-04\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7486e-07 - mse: 4.7486e-07 - mae: 5.9147e-04\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7168e-07 - mse: 4.7168e-07 - mae: 5.8956e-04\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6832e-07 - mse: 4.6832e-07 - mae: 5.8746e-04\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6541e-07 - mse: 4.6541e-07 - mae: 5.8556e-04\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6226e-07 - mse: 4.6226e-07 - mae: 5.8365e-04\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.5930e-07 - mse: 4.5930e-07 - mae: 5.8184e-04\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5620e-07 - mse: 4.5620e-07 - mae: 5.7983e-04\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5299e-07 - mse: 4.5299e-07 - mae: 5.7774e-04\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4983e-07 - mse: 4.4983e-07 - mae: 5.7583e-04\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.4687e-07 - mse: 4.4687e-07 - mae: 5.7402e-04\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.4386e-07 - mse: 4.4386e-07 - mae: 5.7201e-04\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4082e-07 - mse: 4.4082e-07 - mae: 5.7001e-04\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.3830e-07 - mse: 4.3830e-07 - mae: 5.6839e-04\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.3482e-07 - mse: 4.3482e-07 - mae: 5.6601e-04\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.3240e-07 - mse: 4.3240e-07 - mae: 5.6458e-04\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2895e-07 - mse: 4.2895e-07 - mae: 5.6219e-04\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2654e-07 - mse: 4.2654e-07 - mae: 5.6076e-04\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2324e-07 - mse: 4.2324e-07 - mae: 5.5847e-04\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2085e-07 - mse: 4.2085e-07 - mae: 5.5704e-04\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.1769e-07 - mse: 4.1769e-07 - mae: 5.5475e-04\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 4.1496e-07 - mse: 4.1496e-07 - mae: 5.5304e-04\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1206e-07 - mse: 4.1206e-07 - mae: 5.5103e-04\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0947e-07 - mse: 4.0947e-07 - mae: 5.4932e-04\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0667e-07 - mse: 4.0667e-07 - mae: 5.4741e-04\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.0389e-07 - mse: 4.0389e-07 - mae: 5.4560e-04\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0123e-07 - mse: 4.0123e-07 - mae: 5.4369e-04\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9876e-07 - mse: 3.9876e-07 - mae: 5.4207e-04\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.9561e-07 - mse: 3.9561e-07 - mae: 5.3978e-04\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.9286e-07 - mse: 3.9286e-07 - mae: 5.3797e-04\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9024e-07 - mse: 3.9024e-07 - mae: 5.3606e-04\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8784e-07 - mse: 3.8784e-07 - mae: 5.3444e-04\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8484e-07 - mse: 3.8484e-07 - mae: 5.3234e-04\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8226e-07 - mse: 3.8226e-07 - mae: 5.3062e-04\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8031e-07 - mse: 3.8031e-07 - mae: 5.2938e-04\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7743e-07 - mse: 3.7743e-07 - mae: 5.2719e-04\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7501e-07 - mse: 3.7501e-07 - mae: 5.2567e-04\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7215e-07 - mse: 3.7215e-07 - mae: 5.2347e-04\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6984e-07 - mse: 3.6984e-07 - mae: 5.2204e-04\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6703e-07 - mse: 3.6703e-07 - mae: 5.1985e-04\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6468e-07 - mse: 3.6468e-07 - mae: 5.1823e-04\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6262e-07 - mse: 3.6262e-07 - mae: 5.1689e-04\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5964e-07 - mse: 3.5964e-07 - mae: 5.1460e-04\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5751e-07 - mse: 3.5751e-07 - mae: 5.1308e-04\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5527e-07 - mse: 3.5527e-07 - mae: 5.1165e-04\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5255e-07 - mse: 3.5255e-07 - mae: 5.0964e-04\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5049e-07 - mse: 3.5049e-07 - mae: 5.0812e-04\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4800e-07 - mse: 3.4800e-07 - mae: 5.0640e-04\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4549e-07 - mse: 3.4549e-07 - mae: 5.0449e-04\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4349e-07 - mse: 3.4349e-07 - mae: 5.0316e-04\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4084e-07 - mse: 3.4084e-07 - mae: 5.0116e-04\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3848e-07 - mse: 3.3848e-07 - mae: 4.9934e-04\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3650e-07 - mse: 3.3650e-07 - mae: 4.9801e-04\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3430e-07 - mse: 3.3430e-07 - mae: 4.9639e-04\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3196e-07 - mse: 3.3196e-07 - mae: 4.9458e-04\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2961e-07 - mse: 3.2961e-07 - mae: 4.9286e-04\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2737e-07 - mse: 3.2737e-07 - mae: 4.9124e-04\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2498e-07 - mse: 3.2498e-07 - mae: 4.8933e-04\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2315e-07 - mse: 3.2315e-07 - mae: 4.8809e-04\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2076e-07 - mse: 3.2076e-07 - mae: 4.8618e-04\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1847e-07 - mse: 3.1847e-07 - mae: 4.8437e-04\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1658e-07 - mse: 3.1658e-07 - mae: 4.8304e-04\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1439e-07 - mse: 3.1439e-07 - mae: 4.8141e-04\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1247e-07 - mse: 3.1247e-07 - mae: 4.8008e-04\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1062e-07 - mse: 3.1062e-07 - mae: 4.7865e-04\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0799e-07 - mse: 3.0799e-07 - mae: 4.7646e-04\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0613e-07 - mse: 3.0613e-07 - mae: 4.7512e-04\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0397e-07 - mse: 3.0397e-07 - mae: 4.7350e-04\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0192e-07 - mse: 3.0192e-07 - mae: 4.7178e-04\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.0013e-07 - mse: 3.0013e-07 - mae: 4.7035e-04\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9817e-07 - mse: 2.9817e-07 - mae: 4.6883e-04\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9599e-07 - mse: 2.9599e-07 - mae: 4.6701e-04\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9382e-07 - mse: 2.9382e-07 - mae: 4.6520e-04\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9197e-07 - mse: 2.9197e-07 - mae: 4.6387e-04\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9012e-07 - mse: 2.9012e-07 - mae: 4.6253e-04\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8797e-07 - mse: 2.8797e-07 - mae: 4.6072e-04\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8583e-07 - mse: 2.8583e-07 - mae: 4.5891e-04\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8392e-07 - mse: 2.8392e-07 - mae: 4.5738e-04\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8242e-07 - mse: 2.8242e-07 - mae: 4.5624e-04\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8007e-07 - mse: 2.8007e-07 - mae: 4.5414e-04\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7851e-07 - mse: 2.7851e-07 - mae: 4.5300e-04\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7663e-07 - mse: 2.7663e-07 - mae: 4.5147e-04\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7478e-07 - mse: 2.7478e-07 - mae: 4.4994e-04\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7287e-07 - mse: 2.7287e-07 - mae: 4.4842e-04\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7093e-07 - mse: 2.7093e-07 - mae: 4.4670e-04\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6910e-07 - mse: 2.6910e-07 - mae: 4.4518e-04\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6727e-07 - mse: 2.6727e-07 - mae: 4.4365e-04\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6545e-07 - mse: 2.6545e-07 - mae: 4.4203e-04\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6364e-07 - mse: 2.6364e-07 - mae: 4.4050e-04\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6199e-07 - mse: 2.6199e-07 - mae: 4.3926e-04\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6019e-07 - mse: 2.6019e-07 - mae: 4.3774e-04\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5847e-07 - mse: 2.5847e-07 - mae: 4.3631e-04\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5656e-07 - mse: 2.5656e-07 - mae: 4.3468e-04\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5523e-07 - mse: 2.5523e-07 - mae: 4.3364e-04\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5303e-07 - mse: 2.5303e-07 - mae: 4.3154e-04\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5139e-07 - mse: 2.5139e-07 - mae: 4.3030e-04\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4962e-07 - mse: 2.4962e-07 - mae: 4.2877e-04\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4784e-07 - mse: 2.4784e-07 - mae: 4.2725e-04\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4640e-07 - mse: 2.4640e-07 - mae: 4.2610e-04\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4476e-07 - mse: 2.4476e-07 - mae: 4.2467e-04\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4312e-07 - mse: 2.4312e-07 - mae: 4.2324e-04\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4118e-07 - mse: 2.4118e-07 - mae: 4.2143e-04\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3984e-07 - mse: 2.3984e-07 - mae: 4.2048e-04\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3812e-07 - mse: 2.3812e-07 - mae: 4.1885e-04\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3666e-07 - mse: 2.3666e-07 - mae: 4.1752e-04\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3492e-07 - mse: 2.3492e-07 - mae: 4.1599e-04\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3352e-07 - mse: 2.3352e-07 - mae: 4.1485e-04\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3192e-07 - mse: 2.3192e-07 - mae: 4.1342e-04\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3020e-07 - mse: 2.3020e-07 - mae: 4.1189e-04\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2882e-07 - mse: 2.2882e-07 - mae: 4.1075e-04\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2698e-07 - mse: 2.2698e-07 - mae: 4.0884e-04\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2568e-07 - mse: 2.2568e-07 - mae: 4.0789e-04\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2403e-07 - mse: 2.2403e-07 - mae: 4.0627e-04\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2242e-07 - mse: 2.2242e-07 - mae: 4.0493e-04\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2116e-07 - mse: 2.2116e-07 - mae: 4.0369e-04\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1948e-07 - mse: 2.1948e-07 - mae: 4.0216e-04\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1823e-07 - mse: 2.1823e-07 - mae: 4.0112e-04\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1651e-07 - mse: 2.1651e-07 - mae: 3.9940e-04\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1516e-07 - mse: 2.1516e-07 - mae: 3.9825e-04\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1351e-07 - mse: 2.1351e-07 - mae: 3.9673e-04\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1242e-07 - mse: 2.1242e-07 - mae: 3.9577e-04\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1106e-07 - mse: 2.1106e-07 - mae: 3.9444e-04\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0951e-07 - mse: 2.0951e-07 - mae: 3.9301e-04\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0803e-07 - mse: 2.0803e-07 - mae: 3.9158e-04\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0680e-07 - mse: 2.0680e-07 - mae: 3.9053e-04\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0535e-07 - mse: 2.0535e-07 - mae: 3.8910e-04\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0414e-07 - mse: 2.0414e-07 - mae: 3.8805e-04\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0240e-07 - mse: 2.0240e-07 - mae: 3.8614e-04\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0141e-07 - mse: 2.0141e-07 - mae: 3.8538e-04\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9976e-07 - mse: 1.9976e-07 - mae: 3.8366e-04\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9878e-07 - mse: 1.9878e-07 - mae: 3.8290e-04\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9695e-07 - mse: 1.9695e-07 - mae: 3.8090e-04\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9585e-07 - mse: 1.9585e-07 - mae: 3.8004e-04\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9444e-07 - mse: 1.9444e-07 - mae: 3.7851e-04\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9346e-07 - mse: 1.9346e-07 - mae: 3.7775e-04\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9194e-07 - mse: 1.9194e-07 - mae: 3.7613e-04\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9058e-07 - mse: 1.9058e-07 - mae: 3.7489e-04\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8921e-07 - mse: 1.8921e-07 - mae: 3.7336e-04\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8825e-07 - mse: 1.8825e-07 - mae: 3.7260e-04\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8677e-07 - mse: 1.8677e-07 - mae: 3.7098e-04\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8570e-07 - mse: 1.8570e-07 - mae: 3.7012e-04\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8403e-07 - mse: 1.8403e-07 - mae: 3.6821e-04\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8310e-07 - mse: 1.8310e-07 - mae: 3.6745e-04\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8173e-07 - mse: 1.8173e-07 - mae: 3.6592e-04\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8081e-07 - mse: 1.8081e-07 - mae: 3.6516e-04\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7916e-07 - mse: 1.7916e-07 - mae: 3.6325e-04\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7825e-07 - mse: 1.7825e-07 - mae: 3.6249e-04\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7690e-07 - mse: 1.7690e-07 - mae: 3.6097e-04\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7599e-07 - mse: 1.7599e-07 - mae: 3.6020e-04\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7436e-07 - mse: 1.7436e-07 - mae: 3.5830e-04\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7346e-07 - mse: 1.7346e-07 - mae: 3.5753e-04\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7213e-07 - mse: 1.7213e-07 - mae: 3.5601e-04\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7123e-07 - mse: 1.7123e-07 - mae: 3.5524e-04\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6963e-07 - mse: 1.6963e-07 - mae: 3.5334e-04\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6882e-07 - mse: 1.6882e-07 - mae: 3.5267e-04\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6764e-07 - mse: 1.6764e-07 - mae: 3.5124e-04\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6647e-07 - mse: 1.6647e-07 - mae: 3.5009e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label='loss')\n",
        "plt.plot(history.history['mae'], label='mae')\n",
        "#epoch 별 훈련 손실 및 평가 지표의 시각화\n",
        "#앞 부분의 에폭은 손실이 급격히 감소하는 것을 확인할 수 있음."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "DJjpULa8CjCc",
        "outputId": "ded5d6a0-b228-4b0b-8a05-38c7447efe2e"
      },
      "execution_count": 589,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd410648990>]"
            ]
          },
          "metadata": {},
          "execution_count": 589
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'],label='loss')\n",
        "plt.plot(history.history['mae'], label='mae')\n",
        "plt.xlim(-1,20)\n",
        "plt.legend()\n",
        "# 5에폭까지는 손실이 급격히 갑소하다가 감소폭이 둔화되면서 조금씩 감소되는 것을 확인할 수 있음.\n",
        "# 즉, 모델 훈련 초기 단계에는 학습이 매우 빠른 속도로 진행되다가 일정 에폭 이후에는 학습 속도가 느려지는 패턴이 보임."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "MNCimVeJF24k",
        "outputId": "1cb0f65c-b8f8-4c9a-b93d-543a2591e925"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd4106f6650>"
            ]
          },
          "metadata": {},
          "execution_count": 590
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa10lEQVR4nO3de5RV5Z3m8e9TF0C8EIMsTUCbciQXxBhNQXtJiGm6BdPdIU6cCU56RFtjsqK2mczo0rhMO650EuNMOxnbmDCBCE4MGNSZmo4G49hrqWtFoKDxggSpRhyKEEU05QW5VPGbP84GT50657ynqHMp4PmsVav2ed937/3uXbv2U+/e+9RRRGBmZlZOU6M7YGZmw5/DwszMkhwWZmaW5LAwM7Mkh4WZmSW1NLoDg3HcccfFxIkTG90NM7ODxqpVq16LiHFDXc5BFRYTJ06ks7Oz0d0wMztoSHq5GsvxZSgzM0tyWJiZWZLDwszMkhwWZmaW5LAwM7Mkh4WZmSU5LMzMLOmgep/FAevphlULofUIGHFk7nvr6Lzp7PuI0bnyfXVNzY3uuZnZsHB4hMUfNsMTtwOD/OyO5hF54TG6+PT+ABpdEEb5AXTkwKBqHQ0tI2qyuWZm1XZ4hMUfnQ1/+wb07oI9O2D3O7DnXdiTfd+9I296X92OrO2OgnY7YNdb8ParWdsd780XfYPrV1NLiVFNsTDKAmjE6EGE0UiQarNPzeywcniEBeROmq2jcl+j31/95UdA355csOzeURBGeQFUNKjygyn72rF9YN3ePYPc5qbiYdRvNDS6fwANCKMyl+1aj3AYmR0mKgoLSbOAHwDNwE8i4nsF9SOBRcAngO3AFyNik6SxwFJgKnBPRFydN88ngHuAI4CHgWvjYP6MVyl3WallBBxxbG3W0ben/0im33QlYZTX7q2t/UNt9w7o2zXIDikvfPLDqNhlu8IAqmDU1DoamvwMhtlwkAwLSc3AXcCfAd3ASkkdEfFCXrPLgTci4hRJc4DbgC8CO4GbgSnZV767gS8Dy8mFxSzgkaFtziGuuRWax8CoMbVZ/t6+RBhVetluB7yzbWAY9b47+D61jCoY1ZQaDR3gPSQ/xGBWkUpGFtOArojYCCBpMTAbyA+L2cAt2fRS4B8kKSLeAZ6SdEr+AiV9ADgmIp7OXi8CPo/DorGammHk0bmvWti7NxcYhQFU9LJdkVFTfhi9+wb0bHmvfF/bA32IoWgYFU4fUSSUjigoL6hrGeVLdXZIqCQsxgOb8153A39cqk1E9ErqAcYCr5VZZnfBMscXayjpSuBKgJNOOqmC7tqw1dSUO4mOOBKOPK76y4+A3p0VhlHist2ut+CtVwaG0WAfYkBFQiY/fAouu43ID6WC+0P9As0PMlh9Dfsb3BExD5gH0N7efvDe07Dak947sdbiIQaA3t3vhUd+kPR7QKFUXUH5u2/Am7/LC6wstGLvILe7qSB8Ckc5JUZGA0ZNZYKreYQD6TBXSVhsAU7Mez0hKyvWpltSCzCG3I3ucsuckFim2fCz/yGG99Vm+RHQlxdI/QIoP1QqDKcd26Fnc17dAV6uU3P/UCm8bJc/4ukXQAWX6soFl993NKxVEhYrgUmS2sid0OcA/66gTQcwF/gNcBHweLknmyJiq6Q3JZ1F7gb3JcCdB9B/s0OLlLus1DKydk/VRbz3nqN+YfPuwFFOv7oSwfXOq0VGTjsG36+mlhJBkgqn/EA6snxwNQ/7iynDVnLPZfcgrgaWkXt0dkFErJV0K9AZER3AfOBeSV3A6+QCBQBJm4BjgBGSPg+cnz1J9TXee3T2EXxz26w+8t9zRI0u1xW9f7SjIKCK1ZUIrre2DhxVHcjTdU2tg7g8VyKcBnwvCK7m1urvz2FAB9NbG9rb28OfwW1mQPZ03c4K7g8l7h2VG1X17hx8v/qNkBLhUjaMSgTUiNGDespO0qqIaB/8hvTnMZmZHZyamnInzhGja7eOvXtzYdK7s2AU9G7BdLHvhWXv5t5/VFh2IPeQoMJwOaJqu8JhYWZWSlMTjDwq91WLx72h4B5SKoSK3EsqbLfvf9ftG0lVicPCzKyR+t1DqoHrqvPIs//xjpmZJTkszMwsyWFhZmZJDgszM0tyWJiZWZLDwszMkhwWZmaW5LAwM7Mkh4WZmSU5LMzMLMlhYWZmSQ4LMzNLcliYmVmSw8LMzJIcFmZmluSwMDOzJIeFmZklOSzMzCzJYWFmZkkOCzMzS3JYmJlZksPCzMySHBZmZpbksDAzsySHhZmZJTkszMwsqaKwkDRL0npJXZJuKFI/UtKSrH65pIl5dTdm5eslzcwr/w+S1kp6XtLPJY2qxgaZmVn1JcNCUjNwF3ABMBm4WNLkgmaXA29ExCnAHcBt2byTgTnAqcAs4IeSmiWNB/4GaI+IKUBz1s7MzIahSkYW04CuiNgYEbuBxcDsgjazgYXZ9FJghiRl5YsjYldEvAR0ZcsDaAGOkNQCjAZ+N7RNMTOzWqkkLMYDm/Ned2dlRdtERC/QA4wtNW9EbAH+C/D/gK1AT0Q8Wmzlkq6U1Cmpc9u2bRV018zMqq0hN7glHUtu1NEGfBA4UtJfFWsbEfMioj0i2seNG1fPbpqZWaaSsNgCnJj3ekJWVrRNdllpDLC9zLx/CrwUEdsiYg/wIHDOgWyAmZnVXiVhsRKYJKlN0ghyN6I7Ctp0AHOz6YuAxyMisvI52dNSbcAkYAW5y09nSRqd3duYAawb+uaYmVkttKQaRESvpKuBZeSeWloQEWsl3Qp0RkQHMB+4V1IX8DrZk01Zu/uBF4Be4KqI6AOWS1oKrM7K/xmYV/3NMzOzalBuAHBwaG9vj87OzkZ3w8zsoCFpVUS0D3U5fge3mZklOSzMzCzJYWFmZkkOCzMzS3JYmJlZksPCzMySHBZmZpbksDAzsySHhZmZJTkszMwsyWFhZmZJDgszM0tyWJiZWZLDwszMkhwWZmaW5LAwM7Mkh4WZmSU5LMzMLMlhYWZmSQ4LMzNLcliYmVmSw8LMzJIcFmZmluSwMDOzJIeFmZklOSzMzCzJYWFmZkkOCzMzS3JYmJlZksPCzMySKgoLSbMkrZfUJemGIvUjJS3J6pdLmphXd2NWvl7SzLzy90laKum3ktZJOrsaG2RmZtWXDAtJzcBdwAXAZOBiSZMLml0OvBERpwB3ALdl804G5gCnArOAH2bLA/gB8KuI+AhwOrBu6JtjZma1UMnIYhrQFREbI2I3sBiYXdBmNrAwm14KzJCkrHxxROyKiJeALmCapDHAdGA+QETsjog/DH1zzMysFloqaDMe2Jz3uhv441JtIqJXUg8wNit/umDe8cC7wDbgp5JOB1YB10bEO4Url3QlcCXASSedVEF3zcwG2rNnD93d3ezcubPRXamJUaNGMWHCBFpbW2uy/ErColbrPRO4JiKWS/oBcANwc2HDiJgHzANob2+PuvbSzA4Z3d3dHH300UycOJHchY9DR0Swfft2uru7aWtrq8k6KrkMtQU4Me/1hKysaBtJLcAYYHuZebuB7ohYnpUvJRceZmY1sXPnTsaOHXvIBQWAJMaOHVvTUVMlYbESmCSpTdIIcjesOwradABzs+mLgMcjIrLyOdnTUm3AJGBFRPwe2Czpw9k8M4AXhrgtZmZlHYpBsU+tty15GSq7B3E1sAxoBhZExFpJtwKdEdFB7kb1vZK6gNfJBQpZu/vJBUEvcFVE9GWLvgb4WRZAG4HLqrxtZmbDylFHHcXbb7/d6G4ckIruWUTEw8DDBWXfypveCfybEvP+HfB3RcrXAO2D6ayZmTWG38FtZlZnEcF1113HlClTOO2001iyZAkAW7duZfr06Xz84x9nypQpPPnkk/T19XHppZfub3vHHXc0pM+NehrKzKxh/vP/WcsLv3uzqsuc/MFj+Nu/PLWitg8++CBr1qzhmWee4bXXXmPq1KlMnz6d++67j5kzZ3LTTTfR19fHjh07WLNmDVu2bOH5558H4A9/aMxb0jyyMDOrs6eeeoqLL76Y5uZmjj/+eD796U+zcuVKpk6dyk9/+lNuueUWnnvuOY4++mhOPvlkNm7cyDXXXMOvfvUrjjnmmIb02SMLMzvsVDoCqLfp06fzxBNP8Mtf/pJLL72Ub3zjG1xyySU888wzLFu2jB/96Efcf//9LFiwoO5988jCzKzOPvWpT7FkyRL6+vrYtm0bTzzxBNOmTePll1/m+OOP58tf/jJXXHEFq1ev5rXXXmPv3r184Qtf4Nvf/jarV69uSJ89sjAzq7MLL7yQ3/zmN5x++ulI4vvf/z4nnHACCxcu5Pbbb6e1tZWjjjqKRYsWsWXLFi677DL27t0LwHe/+92G9Fm5984dHNrb26Ozs7PR3TCzg9C6dev46Ec/2uhu1FSxbZS0KiKG/DYFX4YyM7Mkh4WZmSU5LMzMLMlhYWZmSQ4LMzNLcliYmVmSw8LMzJIcFmZmluSwMDOrg02bNvGRj3yESy+9lA996EN86Utf4rHHHuPcc89l0qRJrFixghUrVnD22WdzxhlncM4557B+/XoA+vr6uO6665g6dSof+9jH+PGPf1z3/vvffZjZ4eeRG+D3z1V3mSecBhd8r2yTrq4ufvGLX7BgwQKmTp3Kfffdx1NPPUVHRwff+c53WLRoEU8++SQtLS089thjfPOb3+SBBx5g/vz5jBkzhpUrV7Jr1y7OPfdczj//fNra2qq7DWU4LMzM6qStrY3TTjsNgFNPPZUZM2YgidNOO41NmzbR09PD3Llz2bBhA5LYs2cPAI8++ijPPvssS5cuBaCnp4cNGzY4LMzMaioxAqiVkSNH7p9uamra/7qpqYne3l5uvvlmPvOZz/DQQw+xadMmzjvvPCD3yXp33nknM2fObES3c31s2JrNzKyfnp4exo8fD8A999yzv3zmzJncfffd+0caL774Iu+8805d++awMDMbJq6//npuvPFGzjjjDHp7e/eXX3HFFUyePJkzzzyTKVOm8JWvfKVffT34X5Sb2WHB/6J8aDyyMDOzJIeFmZklOSzMzCzJYWFmh42D6R7tYNV62xwWZnZYGDVqFNu3bz8kAyMi2L59O6NGjarZOvymPDM7LEyYMIHu7m62bdvW6K7UxKhRo5gwYULNlu+wMLPDQmtra13/PcahpqLLUJJmSVovqUvSDUXqR0paktUvlzQxr+7GrHy9pJkF8zVL+mdJ/zjUDTEzs9pJhoWkZuAu4AJgMnCxpMkFzS4H3oiIU4A7gNuyeScDc4BTgVnAD7Pl7XMtsG6oG2FmZrVVychiGtAVERsjYjewGJhd0GY2sDCbXgrMkKSsfHFE7IqIl4CubHlImgD8OfCToW+GmZnVUiVhMR7YnPe6Oysr2iYieoEeYGxi3v8GXA/sLbdySVdK6pTUeajemDIzG+4a8uispL8AXo2IVam2ETEvItojon3cuHF16J2ZmRWqJCy2ACfmvZ6QlRVtI6kFGANsLzPvucDnJG0id1nrTyT9zwPov5mZ1UElYbESmCSpTdIIcjesOwradABzs+mLgMcj986XDmBO9rRUGzAJWBERN0bEhIiYmC3v8Yj4qypsj5mZ1UDyfRYR0SvpamAZ0AwsiIi1km4FOiOiA5gP3CupC3idXACQtbsfeAHoBa6KiL4abYuZmdWIP8/CzOwQ5s+zMDOzunFYmJlZksPCzMySHBZmZpbksDAzsySHhZmZJTkszMwsyWFhZmZJDgszM0tyWJiZWZLDwszMkhwWZmaW5LAwM7Mkh4WZmSU5LMzMLMlhYWZmSQ4LMzNLcliYmVmSw8LMzJIcFmZmluSwMDOzJIeFmZklOSzMzCzJYWFmZkkOCzMzS3JYmJlZksPCzMySHBZmZpbksDAzs6SKwkLSLEnrJXVJuqFI/UhJS7L65ZIm5tXdmJWvlzQzKztR0j9JekHSWknXVmuDzMys+pJhIakZuAu4AJgMXCxpckGzy4E3IuIU4A7gtmzeycAc4FRgFvDDbHm9wH+MiMnAWcBVRZZpZmbDRCUji2lAV0RsjIjdwGJgdkGb2cDCbHopMEOSsvLFEbErIl4CuoBpEbE1IlYDRMRbwDpg/NA3x8zMaqGSsBgPbM573c3AE/v+NhHRC/QAYyuZN7tkdQawvPJum5lZPTX0Breko4AHgK9HxJsl2lwpqVNS57Zt2+rbQTMzAyoLiy3AiXmvJ2RlRdtIagHGANvLzSuplVxQ/CwiHiy18oiYFxHtEdE+bty4CrprZmbVVklYrAQmSWqTNILcDeuOgjYdwNxs+iLg8YiIrHxO9rRUGzAJWJHdz5gPrIuIv6/GhpiZWe20pBpERK+kq4FlQDOwICLWSroV6IyIDnIn/nsldQGvkwsUsnb3Ay+QewLqqojok/RJ4N8Dz0lak63qmxHxcLU30MzMhk65AcDBob29PTo7OxvdDTOzg4akVRHRPtTl+B3cZmaW5LAwM7Mkh4WZmSU5LMzMLMlhYWZmSQ4LMzNLcliYmVmSw8LMzJIcFmZmluSwMDOzJIeFmZklOSzMzCzJYWFmZkkOCzMzS3JYmJlZksPCzMySHBZmZpbksDAzsySHhZmZJTkszMwsyWFhZmZJDgszM0tyWJiZWZLDwszMkhwWZmaW5LAwM7Mkh4WZmSU5LMzMLMlhYWZmSS2N7kA9bHrtHX78xMZ+ZVLedEH7/nUqWVc4rwory86nMnVl5ssrGLC2aq2jwvkKKytdZmF92f1fg306cP3lf8b960rv//LbVHnfqHgdB7hPBx4oZeYbxM+45vt0ML+LA9ZS4XzV2d5yLwe1jop/F0vPVy0VhYWkWcAPgGbgJxHxvYL6kcAi4BPAduCLEbEpq7sRuBzoA/4mIpZVssxqemPHbh5b98r+1xH5tf1e9KvrXwMRBW1LzFfYtnA5VLiOgXX585Xu94B5B9TlraPMfIPZXjM7tKnwhDCggdQMvAj8GdANrAQujogX8tp8DfhYRHxV0hzgwoj4oqTJwM+BacAHgceAD2WzlV1mMe3t7dHZ2Tn4rbS6GhAyVQqkciFXfn0H9gdBubCuRQAP7FvpBR3oHxJltzfxB0BV1lFmmYP7w63gdbn9P4g/sg5kvqH8UUnFx03pdaSOhXNPGbcqItoL1zxYlYwspgFdEbERQNJiYDaQf2KfDdySTS8F/kG5sdZsYHFE7AJektSVLY8KlmkHqQHD7LIj4uoPl82s+iq5wT0e2Jz3ujsrK9omInqBHmBsmXkrWSYAkq6U1Cmpc9u2bRV018zMqm3YPw0VEfMioj0i2seNG9fo7piZHZYqCYstwIl5rydkZUXbSGoBxpC70V1q3kqWaWZmw0QlYbESmCSpTdIIYA7QUdCmA5ibTV8EPB65OzAdwBxJIyW1AZOAFRUu08zMhonkDe6I6JV0NbCM3GOuCyJiraRbgc6I6ADmA/dmN7BfJ3fyJ2t3P7kb173AVRHRB1BsmdXfPDMzq4bko7PDiR+dNTMbHElVeXR22N/gNjOzxnNYmJlZksPCzMySHBZmZpZ0UN3glrQNeHkIizgOeK1K3am24dw3cP+Gyv0bGvfvwH04Io4e6kIOqn9RHhFDegu3pM5qPBVQC8O5b+D+DZX7NzTu34GTVJVHSH0ZyszMkhwWZmaWdLiFxbxGd6CM4dw3cP+Gyv0bGvfvwFWlbwfVDW4zM2uMw21kYWZmB8BhYWZmSYdcWEiaJWm9pC5JNxSpHylpSVa/XNLEOvbtREn/JOkFSWslXVukzXmSeiStyb6+Va/+ZevfJOm5bN0DHrlTzn/P9t+zks6sY98+nLdf1kh6U9LXC9rUdf9JWiDpVUnP55W9X9KvJW3Ivh9bYt65WZsNkuYWa1Oj/t0u6bfZz+8hSe8rMW/ZY6GG/btF0pa8n+FnS8xb9ne9Rn1bktevTZLWlJi3Hvuu6PmkZsdfRBwyX+T+3fm/ACcDI4BngMkFbb4G/CibngMsqWP/PgCcmU0fDbxYpH/nAf/YwH24CTiuTP1ngUfIfXj2WcDyBv6sfw/8USP3HzAdOBN4Pq/s+8AN2fQNwG1F5ns/sDH7fmw2fWyd+nc+0JJN31asf5UcCzXs3y3Af6rg51/2d70WfSuo/6/Atxq474qeT2p1/B1qI4tpQFdEbIyI3cBiYHZBm9nAwmx6KTBDkurRuYjYGhGrs+m3gHWU+OzxYWw2sChyngbeJ+kDDejHDOBfImIo7+gfsoh4gtxnuOTLP8YWAp8vMutM4NcR8XpEvAH8GphVj/5FxKMR0Zu9fJrcJ1U2RIn9V4lKftdr1rfsnPFvgZ9Xc52DUeZ8UpPj71ALi/HA5rzX3Qw8Ge9vk/3C9ABj69K7PNnlrzOA5UWqz5b0jKRHJJ1a145BAI9KWiXpyiL1lezjephD6V/URu4/gOMjYms2/Xvg+CJthst+/GtyI8ViUsdCLV2dXSZbUOIySqP336eAVyJiQ4n6uu67gvNJTY6/Qy0sDgqSjgIeAL4eEW8WVK8md2nldOBO4H/VuXufjIgzgQuAqyRNr/P6k5T7KN7PAb8oUt3o/ddP5Mb8w/L5dEk3kfsEy5+VaNKoY+Fu4F8BHwe2krvcM9xcTPlRRd32XbnzSTWPv0MtLLYAJ+a9npCVFW0jqQUYA2yvS+9y62wl94P9WUQ8WFgfEW9GxNvZ9MNAq6Tj6tW/iNiSfX8VeIjccD9fJfu41i4AVkfEK4UVjd5/mVf2XZrLvr9apE1D96OkS4G/AL6UnVAGqOBYqImIeCUi+iJiL/A/Sqy3YfsvO2/8a2BJqTb12nclzic1Of4OtbBYCUyS1Jb99TkH6Cho0wHsu/N/EfB4qV+Wasuuc84H1kXE35doc8K+eyiSppH7GdUlzCQdKenofdPkboQ+X9CsA7hEOWcBPXlD3nop+VddI/dfnvxjbC7wv4u0WQacL+nY7DLL+VlZzUmaBVwPfC4idpRoU8mxUKv+5d8Du7DEeiv5Xa+VPwV+GxHdxSrrte/KnE9qc/zV8m59I77IPa3zIrknJW7Kym4l94sBMIrc5YsuYAVwch379klyQ8JngTXZ12eBrwJfzdpcDawl93TH08A5dezfydl6n8n6sG//5fdPwF3Z/n0OaK/zz/dIcif/MXllDdt/5EJrK7CH3HXfy8ndA/u/wAbgMeD9Wdt24Cd58/51dhx2AZfVsX9d5K5X7zsG9z0d+EHg4XLHQp36d292bD1L7sT3gcL+Za8H/K7Xum9Z+T37jre8to3Yd6XOJzU5/vzvPszMLOlQuwxlZmY14LAwM7Mkh4WZmSU5LMzMLMlhYWZmSQ4LMzNLcliYmVnS/weCX5+jsuexmAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증\n",
        "model.evaluate(x,y) #일반적으로 검증 데이터 셋을 입력하여 검증함. 여기서는 별도의 검증 데이터 셋을 만들지 않아서 훈련 데이터를 대입하여 결과를 확인함.\n",
        "# 두 개의 지표 loss 와 mse 를 확인.\n",
        "# 사전에 검증 데이터를 준비하여 훈련용과 검증용으로 나눈 성능을 평가하는 것이 일반적임. 이런 방법을 교차 검증 cross validation 이라고 함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKi5NB1cGapq",
        "outputId": "8aaec1af-85a2-489a-d6f3-59986c85dbb5"
      },
      "execution_count": 582,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 152ms/step - loss: 1.4410e-04 - mse: 1.4410e-04 - mae: 0.0103\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0001441033382434398, 0.0001441033382434398, 0.010303497314453125]"
            ]
          },
          "metadata": {},
          "execution_count": 582
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#예측\n",
        "#훈력이 완료된 모델의 결과에 predict() 메소드를 사용하여 새로운 입력 데이터를 넣어 주면 모델의 예측값을 얻게 됨.\n",
        "#모델이 예측 결과로 출력하는 값은 32.0...임. 데이터 셋 생성할 때 정의한 y=3x+2 x=10일 때 y를 예측한 것. 수학으로 계산한 것이 아니라 예측을 한 것임. 근사값을 잘 예측함."
      ],
      "metadata": {
        "id": "y99sl3be7lMq"
      },
      "execution_count": 583,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR_Z-OOtvh4I",
        "outputId": "ee3570a5-f531-4f83-b63e-a9106384bb6d"
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.049797]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 584
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUqOZ8I9JYb5",
        "outputId": "514be040-a7c5-4b17-cd0e-e8f1fc0e0c08"
      },
      "execution_count": 585,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20.018623]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 585
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MNIST CNN 강사님 사이트 텐서플로 교재에 있는 내용 꼭 공부하기! 그럼 기초 끝!"
      ],
      "metadata": {
        "id": "VYq7AwjUKdou"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7yuYMw9xuxcX"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Be2ZWdj6hhqH"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dQ4-XV5deITq"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1N_84P9JeGIo"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i0oTIXVhcAKs"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qbB1eeCyb3M1"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LnzkeEnQbRK4"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tLQvtEc6bMXK"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NELRGBPiZrSn"
      },
      "execution_count": 585,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GI9gFj_KU8b4"
      },
      "execution_count": 585,
      "outputs": []
    }
  ]
}